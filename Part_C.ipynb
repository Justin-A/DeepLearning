{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_train shape: (50000, 10)\n",
      "y_test shape: (10000, 10)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Justin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 6, 6, 96)          34944     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 6, 6, 96)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 6, 6, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 6, 6, 256)         614656    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 256)         884992    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 58,322,314\n",
      "Trainable params: 58,322,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 96, kernel_size = (11, 11), strides = (4, 4), padding = 'valid', input_shape = x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), strides = (1, 1), padding = \"same\")) # stride 2 -> 1\n",
    "\n",
    "model.add(Conv2D(filters = 256, kernel_size = (5, 5), strides = (1, 1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), strides = (1, 1), padding = \"same\")) # stride 2 -> 1\n",
    "\n",
    "model.add(Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), strides = (1, 1), padding = \"same\")) # stride 2 -> 1\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "\toptimizer=tf.keras.optimizers.Adam(lr=0.0001, decay=1e-8),\n",
    "\tmetrics=['accuracy'])\n",
    "model.load_weights('saved_models/A_Model_Weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 29, 29, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 107648)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               53824500  \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 53,924,294\n",
      "Trainable params: 53,924,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3_1 = Sequential()\n",
    "model3_1.add(Conv2D(filters = 32, kernel_size = (5, 5), strides = (1, 1), padding = 'same', input_shape = x_train.shape[1:]))\n",
    "model3_1.add(Activation('relu'))\n",
    "model3_1.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1), padding = \"valid\"))\n",
    "\n",
    "model3_1.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "model3_1.add(Activation('relu'))\n",
    "model3_1.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1), padding = \"valid\"))\n",
    "\n",
    "model3_1.add(Conv2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "model3_1.add(Activation('relu'))\n",
    "model3_1.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1), padding = \"valid\"))\n",
    "\n",
    "model3_1.add(Flatten())\n",
    "model3_1.add(Dense(500))\n",
    "model3_1.add(Activation('relu'))\n",
    "model3_1.add(Dense(num_classes))\n",
    "model3_1.add(Activation('softmax'))\n",
    "model3_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a) :\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate soft targets\n",
    "from tensorflow.keras.layers import Activation, Lambda, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "temperature = 1.0\n",
    "student_model1 = model\n",
    "soft_model = Model(inputs = student_model1.layers[0].input, outputs = student_model1.layers[-2].output)\n",
    "logits = soft_model.predict(x_train)\n",
    "logits_T = logits / temperature\n",
    "y_train_soft = np.array([softmax(logit) for logit in logits_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge_Distillation_Loss\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras import backend as K\n",
    "def knowledge_distillation_loss(y_true, y_pred, lambda_const):\n",
    "    y_true, logits = y_true[:, :num_classes], y_true[:, num_classes:]\n",
    "    y_soft = K.softmax(logits / temperature)\n",
    "    y_pred, y_pred_soft = y_pred[:, :num_classes], y_pred[:, num_classes:]\n",
    "    return lambda_const * categorical_crossentropy(y_true, y_pred) + (1-lambda_const) * categorical_crossentropy(y_soft, y_pred_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_1.compile(loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, lambda_const = 0),\n",
    "               optimizer=tf.keras.optimizers.Adam(lr=0.0001, decay=1e-8), \n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "\twidth_shift_range=0.1,\n",
    "\theight_shift_range=0.1,\n",
    "\thorizontal_flip=True,  # randomly flip images\n",
    "\tvertical_flip=True)  # randomly flip images\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Justin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1019 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 2/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1013 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 3/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 0.0000e+00 - acc: 0.1036 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 4/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 5/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 32s 166ms/step - loss: 0.0000e+00 - acc: 0.1016 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 6/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.1021 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 7/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 8/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 9/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 10/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 0.0000e+00 - acc: 0.1035 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 11/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.1038 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 12/200\n",
      "10000/10000 [==============================] - 1s 119us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.1035 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 13/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 33s 171ms/step - loss: 0.0000e+00 - acc: 0.1013 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 14/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 161ms/step - loss: 0.0000e+00 - acc: 0.1022 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 15/200\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.1038 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 16/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 0.0000e+00 - acc: 0.1031 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 17/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1023 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 18/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 19/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.1040 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 20/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 21/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1026 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 22/200\n",
      "10000/10000 [==============================] - 1s 96us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1006 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 23/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.1010 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 24/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1041 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 25/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0997 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 26/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.1045 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 27/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 28/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 143ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 29/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 0.0000e+00 - acc: 0.1021 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 30/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 31/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 143ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 32/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 33/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1035 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 34/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 143ms/step - loss: 0.0000e+00 - acc: 0.1019 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 35/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1021 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 36/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1011 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 37/200\n",
      "10000/10000 [==============================] - 1s 96us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1015 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 38/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1021 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 39/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1026 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 40/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 0.0000e+00 - acc: 0.1038 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 41/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1042 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 42/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 43/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1019 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 44/200\n",
      "10000/10000 [==============================] - 1s 96us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1022 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 45/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1028 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 46/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 47/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1023 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 48/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1046 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 49/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 50/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 51/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 52/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1039 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 53/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 54/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 55/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1035 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 56/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1026 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 57/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 58/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 59/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 60/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1035 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 61/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1045 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 62/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 63/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 64/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 65/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1023 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 66/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1028 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 67/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 144ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 68/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1022 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 69/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1019 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 70/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 71/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1036 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 72/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1022 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 73/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 74/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 28s 145ms/step - loss: 0.0000e+00 - acc: 0.1023 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 75/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 145ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 76/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 0.0000e+00 - acc: 0.1019 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 77/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 78/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1028 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 79/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 80/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 0.0000e+00 - acc: 0.1015 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 81/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 82/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1018 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 83/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 84/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 85/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 86/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1012 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 87/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1028 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 88/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.1022 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 89/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 90/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.1004 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 91/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1013 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 92/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 93/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 146ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 94/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1034 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 95/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1014 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 96/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1010 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 97/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 147ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 98/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1031 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 99/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 100/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1028 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 101/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 0.0000e+00 - acc: 0.1041 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 102/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 103/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 104/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 105/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 106/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.1041 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 107/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 32s 161ms/step - loss: 0.0000e+00 - acc: 0.1016 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 108/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.1015 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 109/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.1019 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 110/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.1038 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 111/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 112/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 113/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1026 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 114/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1004 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 115/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1023 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 116/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1009 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 117/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1037 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 118/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 119/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1046 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 120/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 121/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 122/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1040 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 123/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1031 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 124/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1043 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 125/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 126/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 127/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1040 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 128/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1031 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 129/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1013 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 130/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 131/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 132/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 133/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 134/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 135/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1015 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 136/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 137/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1037 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 138/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 139/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1034 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 140/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 141/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1043 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 142/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1019 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 143/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1021 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 144/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 145/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1039 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 146/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1038 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 147/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 148/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1028 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 149/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1026 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 150/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 151/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1038 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 152/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1041 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 153/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1026 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 154/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1019 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 155/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1023 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 156/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1015 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 157/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 158/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1034 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 159/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 160/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1039 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 161/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1029 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 162/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 163/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 164/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 165/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 166/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1010 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 167/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1031 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 168/200\n",
      "10000/10000 [==============================] - 1s 97us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1028 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 169/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1026 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 170/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1018 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 171/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1021 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 172/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1035 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 173/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1023 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 174/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1021 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 175/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1044 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 176/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1052 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 177/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 178/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 179/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1028 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 180/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 181/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1032 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 182/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 151ms/step - loss: 0.0000e+00 - acc: 0.1033 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 183/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 184/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1035 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 185/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 186/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1038 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 187/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1017 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 188/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1020 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 189/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 190/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1027 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 191/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1022 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 192/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1057 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 193/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1018 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 194/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1025 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 195/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1030 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 196/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1040 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 197/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1024 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 198/200\n",
      "10000/10000 [==============================] - 1s 99us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.1043 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 199/200\n",
      "10000/10000 [==============================] - 1s 100us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1010 - val_loss: 0.0000e+00 - val_acc: 0.1035\n",
      "Epoch 200/200\n",
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1016 - val_loss: 0.0000e+00 - val_acc: 0.1035\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "hist3_1 = model3_1.fit_generator(datagen.flow(x_train, y_train,\n",
    "\tbatch_size=batch_size),\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=(x_test, y_test),\n",
    "\tworkers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\Justin\\Desktop\\Assignment1\\saved_models\\C_Model1_Weights.h5 \n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, 'C_Model1_Weights.h5')\n",
    "model3_1.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 146us/sample - loss: 0.0000e+00 - acc: 0.1085\n",
      "Train loss: 0.0\n",
      "Train accuracy: 0.10848\n",
      "10000/10000 [==============================] - 1s 146us/sample - loss: 0.0000e+00 - acc: 0.1035\n",
      "Test loss: 0.0\n",
      "Test accuracy: 0.1035\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "train_scores = model3_1.evaluate(x_train, y_train, verbose=1)\n",
    "print('Train loss:', train_scores[0])\n",
    "print('Train accuracy:', train_scores[1])\n",
    "test_scores = model3_1.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', test_scores[0])\n",
    "print('Test accuracy:', test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsvXmYHVWdPv5+qupuvac7nYUsBCGISSAhJIHIMiAQcBBxVCQMKAQUkGHG5auODqMgjoq/cRkBRVBB3AIIgwICmcSAoEBIQhaykj3d6XSS3pe7VtX5/VF1Tp2qW3fp5XbfJPU+T570vbeWU1Wnzue872c5xBhDgAABAgQIMFgoo92AAAECBAhwdCMwJAECBAgQYEgIDEmAAAECBBgSAkMSIECAAAGGhMCQBAgQIECAISEwJAECBAgQYEgIDEmAAHlARL8iov8qctu9RHRJqdsUIEC5ITAkAQIECBBgSAgMSYAAxwGISBvtNgQ4dhEYkgBHPWxJ6ctEtJGI+onol0Q0noheJKJeIlpBRGOk7T9MRJuJqIuIXiGi90m/nUlEb9v7PQEg6jnXh4hovb3v60R0RpFtvIKI1hFRDxE1EdHdnt/Ps4/XZf9+o/19jIh+QET7iKibiP5mf3chETX73IdL7L/vJqKniOi3RNQD4EYiWkBEb9jnOEhEDxBRWNp/JhEtJ6IOIjpERP9BRBOIKE5EDdJ2ZxHRESIKFXPtAY59BIYkwLGCjwG4FMCpAK4E8CKA/wAwFlY//zcAIKJTASwF8HkAjQBeAPAcEYXtQfWPAH4DoB7AH+zjwt53LoBHANwKoAHAQwCeJaJIEe3rB/ApAHUArgDwWSL6iH3cqXZ777fbNAfAenu/7wM4C8D77TZ9BYBZ5D25CsBT9jl/B8AA8AX7niwEcDGA2+02VANYAeAlACcAOAXAXxhjrQBeAfAJ6bjXA3icMZYpsh0BjnEEhiTAsYL7GWOHGGMHALwGYBVjbB1jLAXgGQBn2ttdA+DPjLHl9kD4fQAxWAP1OQBCAP6HMZZhjD0FYLV0js8AeIgxtooxZjDGHgOQsvfLC8bYK4yxdxhjJmNsIyxj9g/2z9cBWMEYW2qft50xtp6IFAA3AfgcY+yAfc7X7WsqBm8wxv5onzPBGFvLGHuTMaYzxvbCMoS8DR8C0MoY+wFjLMkY62WMrbJ/ewyW8QARqQCuhWVsAwQAEBiSAMcODkl/J3w+V9l/nwBgH/+BMWYCaAIwyf7tAHNXMt0n/X0igP9nS0NdRNQFYIq9X14Q0dlE9LItCXUDuA0WM4B9jF0+u42FJa35/VYMmjxtOJWInieiVlvu+k4RbQCAPwGYQUTvgcX6uhljbw2yTQGOQQSGJMDxhhZYBgEAQEQEaxA9AOAggEn2dxxTpb+bAHybMVYn/atgjC0t4ry/B/AsgCmMsVoAPwPAz9ME4GSffdoAJHP81g+gQroOFZYsJsNb2vtBANsATGeM1cCS/gq1AYyxJIAnYTGnTyJgIwE8CAxJgOMNTwK4gogutp3F/w+WPPU6gDcA6AD+jYg0IvoogAXSvj8HcJvNLoiIKm0nenUR560G0MEYSxLRAgD/LP32OwCXENEn7PM2ENEcmy09AuCHRHQCEalEtND2ybwLIGqfPwTgPwEU8tVUA+gB0EdEpwH4rPTb8wAmENHniShCRNVEdLb0+68B3AjgwwB+W8T1BjiOEBiSAMcVGGPbYen998Oa8V8J4ErGWJoxlgbwUVgDZicsf8r/SvuugeUnecD+fae9bTG4HcA9RNQL4BuwDBo/7n4A/wjLqHXAcrTPtn/+EoB3YPlqOgB8D4DCGOu2j/kLWGyqH4ArissHX4JlwHphGcUnpDb0wpKtrgTQCmAHgIuk3/8Oy8n/tu1fCRBAgIKFrQIECFAMiGglgN8zxn4x2m0JUF4IDEmAAAEKgojmA1gOy8fTO9rtCVBeCKStAAEC5AURPQYrx+TzgREJ4IeSGhIiupyIthPRTiL6qs/vF9hZxDoRfdzz2w1EtMP+d4P0fZiIHiaid4loGxF9zHvcAAECDB8YYzcwxmoZY78a7bYEKE+UrP6OHY74E1gOvGYAq4noWcbYFmmz/bCclV/y7FsP4C4A82CFMK619+0EcCeAw4yxU+2ErfpSXUOAAAECBCiMUhZyWwBgJ2NsNwAQ0eOwSjYIQ8KjP4jIW/LhMgDLGWMd9u/LAVwOKxv4JgCn2fubsCJv8mLs2LFs2rRpQ7uaAAECBDjOsHbt2jbGmDc/KQulNCST4M6sbQZwdo5ti9l3EhHV2Z+/RUQXwsrEvYMxdsizP4joFgC3AMDUqVOxZs2agbU+QIAAAY5zENG+wluV1kdCPt8VGyKWa18NwGQAf2eMzYWVQPZ9vwMwxh5mjM1jjM1rbCxoUAMECBAgwCBRSkPSDKv0BMdkWOUphrJvO4A4rCJ8gFWdde7QmhkgQIAAAYaCUhqS1QCmE9FJdnnuxbBqDRWDZQAWEdEYstaRWARgmV1M7zkAF9rbXQzJ5xIgQIAAAUYeJfORMMZ0IroDllFQATzCGNtMRPcAWMMYe9ZOcnoGwBgAVxLRNxljMxljHUT0LTglvO/hjncA/w7gN0T0PwCOAFgymPZlMhk0NzcjmUwO4SoDjCSi0SgmT56MUChYTylAgHLCcZHZPm/ePOZ1tu/ZswfV1dVoaGiAu9hrgHIEYwzt7e3o7e3FSSedNNrNCRDguAARrWWMzSu03XGb2Z5MJgMjchSBiNDQ0BAwyAAByhDHrSEBEBiRowzB8woQoDxxXBuSAAECBDhasKWlB2/v7xztZvgiMCSjhPb2dsyZMwdz5szBhAkTMGnSJPE5nU4XdYwlS5Zg+/btAz73FVdcgfPPP3/A+wUIEGD08MPl2/HN58ozSLWUme0B8qChoQHr168HANx9992oqqrCl77kKjkGxhgYY1AUf3v/6KOPDvi87e3teOeddxCNRrF//35MnTq18E6DgK7r0LSgewUIMFxI6SbSureaVHkgYCRlhp07d2LWrFm47bbbMHfuXBw8eBC33HIL5s2bh5kzZ+Kee+4R25533nlYv349dF1HXV0dvvrVr2L27NlYuHAhDh8+7Hv8p556Ch/5yEdwzTXX4IknxAJ5aG1txVVXXYUzzjgDs2fPxqpVqwBYxop/t2SJFWl9/fXX449//KPYt6qqCgCwYsUKXHLJJVi8eDHOPPNMAMCVV16Js846CzNnzsQvfuGsh/TnP/8Zc+fOxezZs7Fo0SIYhoFTTjkFHR1WlLdhGHjPe94jPgcIcLzDZAymWZ5RtsGUEcA3n9uMLS09w3rMGSfU4K4rZw5q3y1btuDRRx/Fz372MwDAvffei/r6eui6josuuggf//jHMWPGDNc+3d3d+Id/+Afce++9+OIXv4hHHnkEX/1qVuV+LF26FN/97ndRW1uL66+/Hl/+8pcBAP/yL/+CSy+9FHfccQd0XUc8HseGDRvwve99D6+//jrq6+uLGtTffPNNbNmyRTCdxx57DPX19YjH45g3bx4+9rGPIZVK4bOf/Sxee+01nHjiiejo6ICqqrj22mvx+9//HnfccQeWLVuG+fPno74+KO4cIAAA6AaDUabpGgEjKUOcfPLJmD9/vvi8dOlSzJ07F3PnzsXWrVuxZUu2ThqLxfDBD34QAHDWWWdh7969WdscOHAA+/fvxznnnIMZM2bAMAxs27YNAPDKK6/g1ltvBQBomoaamhqsXLkS11xzjRjMixnUFy5c6JLLfvSjHwmW1NzcjF27duGNN97ARRddhBNPPNF13JtvvhmPPfYYAOCRRx4RDChAgAABIyl7DJY5lAqVlZXi7x07duDHP/4x3nrrLdTV1eH666/3zaUIh8Pib1VVoet61jZPPPEE2tvbRUJfd3c3Hn/8cdx9990AssNrGWO+IbeapsE0La3WMAzXueS2r1ixAq+++irefPNNxGIxnHfeeUgmkzmPO23aNIwZMwYvv/wy1q1bh0WLFvnenwABjkfoZsBIAgwSPT09qK6uRk1NDQ4ePIhly5YN+lhLly7FihUrsHfvXuzduxdvvfUWli5dCgC46KKLhJRmGAZ6enpwySWX4PHHHxeSFv9/2rRpWLt2LQDgmWeegWEYvufr7u5GfX09YrEYNm/ejNWrrYo35557LlauXIl9+/a5jgtYrOS6667D4sWLcwYZBAhwPMI0GYwyZSTBm1rmmDt3LmbMmIFZs2bhM5/5DM4999xBHWfXrl1obW3FvHlOtYPp06cjEolg7dq1eOCBB7Bs2TKcfvrpmDdvHrZt24YzzjgDX/nKV3DBBRdgzpw5wp9y6623Yvny5ViwYAHWr1+PSCTie84rrrgC8Xgcs2fPxj333IOzz7aWoxk/fjwefPBBXHXVVZg9ezauu+46sc8//dM/obu7GzfeeOOgrjNAgGMVRhlLW8dtra2tW7fife973yi1KEAuvPnmm/ja176Gl19+2ff34LkFOF5x+f+8is54Gqv+45IRO2extbYCH0mAssG3v/1tPPzww3j88cdHuykBApQdTMZglGcaSSBtBSgf3Hnnndi3bx8WLlw42k0JEKDsYJgMZpkqSIEhCRAgQICjAIbJoJcpJQkMSYAAAQIcBTAYQ5n62gNDEiBAgABHAwwjCP8NECBAgABDgMGChMQAHgxHGXnAKiXS2tqa8/d0Oo36+np8/etfH45mBwgQwAfJjIGvPLUBh3tLt4KnYaJs80gCQzJK4GXk169fj9tuuw1f+MIXxGe53EkhFDIkL730EmbMmOGq9FsK+JVkCRDgeMH21l48uaYZq/eUbuEpwzQDRhKgeDz22GNYsGAB5syZg9tvvx2maULXdXzyk5/E6aefjlmzZuG+++7DE088gfXr1+Oaa67JyWSWLl2KL37xixg/frwoUQIAq1atwsKFCzF79mycffbZiMfj0HUdX/jCFzBr1iycccYZ+OlPfwoAmDx5Mrq6ugBYCYOXXGIlRP3nf/4nbr31Vlx66aVYsmQJdu3ahfPPPx9nnnkmzjrrLFGKHgC+853v4PTTT8fs2bNx5513Yvv27ViwYIH4fevWra7PAQIcTehLWROpUg70hsnAmFUDr9wQJCQCwItfBVrfGd5jTjgd+OC9A95t06ZNeOaZZ/D6669D0zTccsstePzxx3HyySejra0N77xjtbOrqwt1dXW4//778cADD2DOnDlZx+rv78df//pXPProo2htbcXSpUsxf/58JJNJLF68GE8//TTmzp2L7u5uRCIR/PSnP0VLSws2bNgAVVWLKhu/bt06vPrqq4hGo4jH41i+fDmi0Si2bduGG264AatWrcJzzz2HF198EW+99RZisRg6OjpQX1+PaDSKTZs2YdasWXj00UeDar8BjloIQ2KWLjyXq1qGyaCp2UVPRxMBIykzrFixAqtXr8a8efMwZ84c/PWvf8WuXbtwyimnYPv27fjc5z6HZcuWoba2tuCxnn32WVx66aWIRqO4+uqr8fTTT8M0TWzduhVTp07F3LlzAQC1tbVQVRUrVqzAbbfdBlVVARRXNv6qq65CNBoFAKRSKdx8882YNWsWFi9eLMrdr1ixAjfddBNisZjruDfffDMeffRR6LqOP/zhD7j22msHfsMCBCgD9CUtQ6IbpWMLOq+4HTCSMsUgmEOpwBjDTTfdhG9961tZv23cuBEvvvgi7rvvPjz99NN4+OGH8x5r6dKlWLVqFaZNmwYAOHz4MF599VXU1NT4lnEvpmy8t4S9XDb+Bz/4AaZMmYLf/va3yGQyYuXEXMe9+uqr8Z3vfAfnnnsuFi5ciLq6urzXEyBAuaI/bRmSUmaec7JTQtIzaJSUkRDR5US0nYh2ElHWcn1EdAERvU1EOhF93PPbDUS0w/53g/T9K/Yx19v/xpXyGkYal1xyCZ588km0tbUBsKK79u/fjyNHjoAxhquvvhrf/OY38fbbbwMAqqur0dvbm3Wczs5OrFq1Cs3NzaJs/H333YelS5di5syZ2LdvnzhGT08PDMPAokWL8OCDD4qy8H5l459++umcbe/u7sbEiRNBRHjssceElrto0SL88pe/RCKRcB23oqICH/jAB3DHHXcEslaAoxq9nJGUMKqKM5FyZCQlMyREpAL4CYAPApgB4FoimuHZbD+AGwH83rNvPYC7AJwNYAGAu4hojLTJdYyxOfY//8XJj1KcfvrpuOuuu3DJJZfgjDPOwKJFi3Do0CE0NTWJcu6f+cxn8J3vfAcAsGTJEnz605/OcrY//fTTuPTSSxEKhcR3H/nIR/DMM89AURQsXboUn/3sZ8Wa6alUCrfeeismTJgg1mh/8sknAQB33303br/9dpx//vl5I8ruuOMO/OIXv8A555yDffv2ifLyH/rQh3D55ZcLue5HP/qR2Oe6665DKBTCxRdfPKz3MUCAkUS/7SMpVXguY04yYjkmJZasjDwRLQRwN2PsMvvz1wCAMfZdn21/BeB5xthT9udrAVzIGLvV/vwQgFcYY0uJ6BUAX2KMrfEeJxeCMvLli3vvvRepVAp33XVXUdsHzy1AOeIbf9qEX7+xD3ddOQNLzj1p2I9vmAwn/8cLAIB1X78UYyqLTxEYCsqhjPwkAE3S52ZYDGOw+06SPj9KRAaApwH8F/OxhkR0C4BbALjWEA9QPrjyyivR1NSElStXjnZTAgQYEpyordJMzHXJMVKO0lYpDYlffFqxdyDfvtcxxg4QUTUsQ/JJAL/O2pixhwE8DFiMpMjzBhhBPPfcc6PdhAABhgU8aqtUhkR2sJdjdnspne3NAKZInycDaBnqvoyxA/b/vbB8K4POYivHxJ4AuRE8rwDlCh61VSpnu8xCSunQHyxKaUhWA5hORCcRURjAYgDPFrnvMgCLiGiM7WRfBGAZEWlENBYAiCgE4EMANg2mcdFoFO3t7cHgdJSAMYb29naRsxIgQDmh1IzEkPJTytHZXjJpizGmE9EdsIyCCuARxthmIroHwBrG2LNENB/AMwDGALiSiL7JGJvJGOsgom/BMkYAcI/9XSUsgxKyj7kCwM8H077JkyejubkZR44cGeKVBhgpRKNRTJ48ebSbESBAFkrtI5EZSTmukljShETG2AsAXvB89w3p79WwZCu/fR8B8Ijnu34AZw1H20KhEE46afijKwIECHD8oeSGxCxvRhKUSAkQIECAIaI/ZSXxlsxHYpY3IwkMSYAAAQIMAabJBCMp1SAvS1vluGx7YEgCBAgQYAiIZwzxd6mKNpa7sz0wJAECBAgwBPCILaB0ZeTL3dkeGJIAAQIEGAK4rAWULus8cLYHCBAgwDEMlyEZiaitgJEEOJbwwModWLO38CqKAQIcy+iXDEnJfCRy1FbASAIcS/jJy7vw/MaDo92MAEVizd4OnHH3MnTF04U3DlA0epOll7ZMFkhbAY5RZAwTKd0ovGGAssDOw33oSeo40psa7aYcU+DSlkKlrP4bSFsBhhktXQms3dc5qm1gjEE3GVKZMgxqD+CLpB2mmtKDZzac4NJWbSw0MgmJZfj4AkNyFOKhv+7Cv/zu7VFtA39hksPESAyT4StPbcCWlp5hOV6AbCRtA5Ipx4y2oxh9kiEplf/CJW0FjCTAcCCZMRFP64U3LCG4UzE5TIykoz+NJ9c04+8724bleAGywRlJpkQO4eMVfSkdYVVBLKyVjJHoroTE8psIBIbkKITJ2KgPBhm7Mw+Xj4QbxnQwWy4ZuNFPB9LWsKIvqaMyokJTqHQLWwUlUgIMNwzGXEtvjgYy9mA0XIyEF70LZJfSwWEkwT0eTvSndFRFNSglNCR6kJAYYLjBmCVPjOaiXMJHkhleRhIMcqUDZ4+Bs3140ZvSURnWSstIguq/AYYbvLOOprzFB/zhGpT604F+X2pw9jjaxnpjcxfe2nPsJLKmdBPRkApVoZIpBUGJlADDDj4jGc0BwXG2DxMjsSNfAv2+dCgXaetHy9/Ft/+8ZVTbMJzQDRMhlaASlSw0Vy+Skazcdgiff3xdaRqRB4EhOQpRFobEHGYfSbo8BrljGdyQ5DLWa/d1jkjUXDJjHlPyWsYwoSkKNLV0jKTYzPY3drWPSrWJwJAcheB9dTQjnNK61ZmHPWrrGBpgyg2FpK37/rID9764reTtyBhmycJkRwMZgyGkKVBL6CMpVtrKGGxU7m1gSI5C8ISkUhSIe3t/J5Ztbi24HZ95DVdmexC1VXokCzjb42l92KTKfMgYJvRj6DnrpomQYklbI1FGPp+0xSeXI13YURvRswUYFrASSls/WbkTOw734bKZE/Jux53iacOEYTKoCg3pvE7U1rEzUy03OIzE/x4nMsaIsNy0Mfp5UMMJ3WDQVAJjI1P9N98j4oxeNxnCQ3wnB4KAkRyFcKK2hv+lP9CVcK2vkAvyjHI45CjOSI63hMQ/rjuA9U1dvr+ldAM/XP7usLGEVAFneyJtjEjtNEvaGtp5/vftZqzbP7r15jgyhglNHUFpKw8j4c92pCO7AkNylKCzP42WrgQAgPcR7qcYTrQUa0ikjjocA10ic3zmkXz7ha343Zv7fH97e18X7vvLDqzZOzwDZiFnezJjjoght6Stwfddxhj+84+b8Jsc922koZvMkraUEkpb8lK7eX0kZtb2I4HAkBwl+N5L23Drb9YCKF3UVm8yg56kjrRuFmQZ8rmHo3Dj8eojSWaMnNfMAxmG654UKtqYyBiCtZQSGd0c0jW19iQRTxtlE/mV0S1GUsqExGKd7XxyaYywdFhSQ0JElxPRdiLaSURf9fn9AiJ6m4h0Ivq457cbiGiH/e8Gn32fJaJNpWx/OaE7kUFPMgOgdIbkYHdS/N1fgJXIGvdwyCHCR1ICllXOSGXMnP4CWe8eDviVkT/QlcDBbovpxtP6iAzO6SFGbe063G8dp1wMickQUhUoCo3MCokettEVT2PXkT4AjjQ80iWUSmZIiEgF8BMAHwQwA8C1RDTDs9l+ADcC+L1n33oAdwE4G8ACAHcR0Rjp948C6CtV28sRuslEBypVZjuXzgAUlLf0EjGS48lHYpgMaSO3nCQGhWG4J4wx34TEL/9hA+58ZhNMkyGZsQb4UuvraX1o0tbuNuvVLxdGwhMSNYVKVr4kHyO5f+VOfOqXbwFwauAdS9LWAgA7GWO7GWNpAI8DuEregDG2lzG2EYC3R1wGYDljrIMx1glgOYDLAYCIqgB8EcB/lbDtIw7TZHhzd3vO3w2TifwR3o+Gm5G0dEmMpECZ+ozLRzKMjOQ4MiRcusplKPiMOzMMA3vGYL795nBvCu19KdegzM/bl9Jx7r0rsSpPvxxsWzJDmDHvOmwbkhGQ4YqBbjBoigJVUUqWwyEbKO852vtS6E5YasWx6GyfBKBJ+txsfzfUfb8F4AcA4vkOQES3ENEaIlpz5MiRIk87enhtZxsWP/wmtrX6L+xkSDPFUoX/uhhJsnhGMhwv9PGY2V4oHFdIW8NwT2TWKEtCvckM+tMGEpns31u7EzjQlcC21t4hn19GxjDB2OAHu11HLGmrXBhJxrRLpCgjs9Su19keTxvimTks9tgxJH5BzMVene++RDQHwCmMsWcKHYAx9jBjbB5jbF5jY2ORpx09dMXTAICOvrTv74bJBF0tVfjvwKQtiZF4Xuhbf7NmwBnSvNbWsZRfUAiFal85evfQ74kcWSff456Ejv6U7jIknClxubGYKL5iYZpO5vVg++/uI+UlbWXsPBJNUUYl/Jfn/zDGhEEZ6QrBpTQkzQCmSJ8nA2gZ4r4LAZxFRHsB/A3AqUT0ypBbWgaI2zNyPjP3QjdNwURE+O8wD7oHuhKojlo5qnwQyQVZ1/eG/25v7cX2HMwqF/h1l4sDdSRQ0JDowze7lAMiUlL0ViJjWIYkbWT9zgMuCgVeDASypOU1kIyxgsalP6WjxQ4KGa7yPEMBY5ZSECpxHolZgJEA1nPLDOPkYyAopSFZDWA6EZ1ERGEAiwE8W+S+ywAsIqIxtpN9EYBljLEHGWMnMMamATgPwLuMsQtL0PYRhzAkOV5aWdoSUVvDPOge7E7iveOr87aDwyVtedqR0s2cBjEXjscVEgtJWykRtTUM0paLkdg+EFu+jKcNf0Nifxcf4LPMB/lavZLd/St34v33rsybaLinzZK1KsPqgCYdTR1xbDrQPcDWFga/Hm5IShUtxQ2DQtmMhD+ftOFEAB4zPhLGmA7gDlhGYSuAJxljm4noHiL6MAAQ0XwiagZwNYCHiGizvW8HLF/IavvfPfZ3Rz1yzboS9kCaS0bQfQzJcHZa02Q42J3AdNuQFJS28iQkpnTTNTAVQlp3XoDjykdSIE/EYQ7DIW1lO9N5OLluMuGslX/nk4nhlLbkwd97Xc2dcRzpTWHxw29iQ45sfx7m+r6JNQOStr7/f9vxuRKUV+fvoGYnJA72ldQNM2+iockYFIItn7l/kwue8vt7zBgSAGCMvcAYO5UxdjJj7Nv2d99gjD1r/72aMTaZMVbJGGtgjM2U9n2EMXaK/e9Rn2PvZYzNKmX7S4H/23IIZ31ruXj4HHEx+8vNSPhEhHek4ZS22vpSyBgM08dVASg8eLjySLyMJGPkvA4/8G1VhYadZZUzUgWq8TqDQvbvyza3DshYy852fr5eKaCivT/ltIv7SNIlkLaka/VOhNK6idpYCCndxBs5IsV4ZOHJjVUDCvJo70u7jOVwgb8HPCFxsJO7Tzz0Bv5nxbs5f9ftenaKku3/iEuy8LEYtXVcwzCZ72Da1BFHT1LHkd6U63veGfpy+CZ0w3G2sxJIW4ft9pxQF0NYUwYmbQ2RkfBrr4uFji9nOw//zfHSp3MwkoPdCdz6m7V4fmOxLkeHNVZHNDHYcEYCwNUf+XnjJXC2y4zE6/vJGAz1lWEAuZNcj/SmUBXRUFcZGhAj6UqkC/r9BgN+L0MqQSGCyTCoJbB3Hu5DU2ci5++myaCQXWHY018Sko9kOAM0BoLAkJQIP/vrLnzg+3/Neui883tnR/xFL8ZHUoqoLX7+irCKqohWBCPxd7brdtbyQHwk3ODWVoRE9MnxAFFEMceAmDZ4non/DHQgM2wubVVHNdEH3YzFaYdlAAAgAElEQVTEiRbkv/eVwtku9Rtv/+VL1oZUypnkeqQvhbFVYUQ0FSm9+L7SncggkTGGfabOn42mWIwEGDgbYIyhL6XnfZ8Nk0FTCIrHoc8YO/alreMZb+5uR2tPUmi6HPwl7UkMTNrSTVNQ2lKUSOHhnzHbkBQskWIyexbmlrb4jGggjITPFGtjIQAjP5saLQhnewFG4icBAcU5wU3b/8GNfU0s5DASyRC198nSFj8+NySDm8lbJVfc+7qc7aaXkZgIq4SopuZhJEk0VkcQ0ayhq9jgjK54RrRpOCEzElW1DMlA+288bcBk+d9n3WRQuB9GMp4p3ZSKuAbS1jEFxpiIEPGWCOcvlnc2WUjaMkwnM7kU4b98UIuFVFQWwUh0e3nRaEh1MRI+AKQHsHgR1+LrbENyvDjciw3/9UpbfPtimMJLm1ux8Lt/EdJVdVQTg6/MSNqk/CUns31o0tZNv1qNe55zr82ej5GkdRNhTUEkpORmJL0ptyEpQt4yTCaudbjlLW40QqoClQbHSHjb8sm6JrMYiVfakicTiYwhxoZjptbW8YyW7iQ67RmQN/rEGzHDwcuo55S2mE/UVgkYSTSkoCqiFuVs11RCRFNcEUEyO4kX6QzlWnxdhaWPHy+FG5MFpS1/Z7sI3y1igG/ttirl7rSZcXU0JO6v25BkO9sFIxnkLH5/ezxL95cZRLaPxERIVRDR1JxLE7T1pdFY5RiSYvwkMvMa7LXkAn8HNZXE4m4DrXPVl3KXN/EDXzxO8TASmWHx4wAYdPTYYBEYkiKxanc71u4rbl0IzkbGVIR8GIm/j6RgHon90pmSr6QUPpKozUgKzdx003rpoyHVJV/Ifxcrb/GXm0tbx0suiSjrPkBnuzdhMB94X9lr51/URB1ne680mWnzcbbzPjBYH0lvUhdh7d5jAz6SneEwEj8DkdINdCcyNiNR7e8K9xX5XRtOfw/g9FWXj2SASkGPYCT5DYlClFWqXn7HZDUjYCRliu+9tA3/vay4sh+bW3qgEPBPZ07GttZe1+xKMBKPIUmIzPbceSSAxUb4hGQ4I5x4G2Oh4nwkVqE6sqUtf0ZS7EsrorYqBi9tyWX2jxYUkrZyJSTy515MQAPvN/vardJ01dGQixWHbF2/zcfZzp9fxmADziI3TYa+tJ41IXFLW+7+m9btyYmm+ob2cvmtsTqCSMhmJEWw3i6XIRlmaUskJDqMZKA+kr4ipC3hbCdy5ZHIfUCujxf4SMoUKd0UDrtC2HygGyc3VuGc99TDMBk2tzgZtbkYSUJEbeX2kQBuiWs4Z+7ckEVtQ9JbwAikhQyh+PpIgOIzovmANRQfyecfX4evPf3OgPcbTXADnKuAYa4SKZkBMBIuvbR0J6AQUBFRXT6S8TVRcS6v30GWTQY6APeldTAGVw0vwJNH4jUkNiOJhhTfitLczyP7SIphJLyOHTD8znaRkKha1X+Bgde54hJjPqnayOFsdz+jwJCUPXSDFW1INrV0Y9akWsyZUgcA2NDkGJJ0AWd7rsFBMBJzYCVSDvUki9LS+YvrSFuFGUlIJURCqutldklb9iByuCeJD93/mlhAyQuHkdg+kkEYktaeFA73JgtvWEbwK1siI1dOQHoAzna+L2PWs42oigix7k3qGFcdgT2RFoyQP0O53wxUEnKc215py7kWbyl5K2pLsUN7sw2XMCRV0UFLW0PNidnfHseH7n8NHTaDy0iMRBsgI/nsb9fiT+sPCN9GvuAZg1k+EqsMi7+01TuKhoSOh5j9efPmsTVr1gx8xxe/CrRas9z1zV1I6wYWTGvIu4tumlizrxNT6yswsTaKVXs6MKkuhiljKgAA21p70JXIoDYWwvsm1Ij9Vu/tgMEsHXTBtPqs4/Lf50+rx/r9nciYDGMrwzhlXHXe9qxv6kRdRRjTGirzbre/I46D3QmcfVIDmjrjONCVwNkn1YN8CzED7x7uRSJtQLOlkZkTawFYL+1Wu2DjaROqURcLoyuRxrbWXrx3fDXG2MZCxr6OfrT2JDG9sRrvHu7F6ZNqURnW8rY3+zq7oCqE0yfVDmi/0cTutj6RCDrvxDHQFPe8buOBLsTTRtZzbutLYeeRPsRCKmZPrst7Dv4sAauMx4TaKJo7rWe76UAPNJXQl9RhMIZYSEUiY4j++vb+TsGAB/pM4mkdGw90QyXCfKk/t/WnsNNeT+TU8dWol/rD2v2ddlKqVTLH+ywP9Saxp60fZ06tQzJtYmtrD2ZMrEFNNJS3La09Sextt3xEJ42txPjqaNHX4UVHfxrvHu7FzIk1qI6GRH+fYZds2XWkD3Om1CFqG7pcMMHw1p4ONFZFUBFWsa8jnvd57jjcK2SsirCKU+3+IN/PCTVRtPZYk6lTxlVhbGUEmHA68MF7B329RLSWMTav0HYBIykSjFnht4VoK58taAqB7GFY3sUJz5OSiuBkrZuMgflU2+ffMeb8WmguZjKGpF5cGK7JLOoMwIk+yTOrYcyq9c+zeeXjcDhRZvbnHPfONAGVCHb0JAYztzEYG/HS2UOFfN/8Ws4vx/v0vCtl5oN8SxSyNHZ+bq678+et2M9AHJ9ZVW2B7IqzhaBLUqzcn+X2eCexzK4nZfWp7POJnA1FESyqmGcu+5gGeh1eyPcGsAwCABA5a18U0w25rJeRlh3ON6nn7xsBrs4iX49RqEOVEAOb9h1vkCz57d/9Cw7Gk1j18YuFruyHnQe6sfj+v+Ghi8/CZTMn4Mavv4TrT5uKO6+wVhn+xoOvY82+TrynphIrl1wIwHIYLv76S6iNWTOczf98GSoj7kdz3Z0vIGMwrL/2Utz836+gO53BolPG4+FP5Z4s7D7ci8U/fBX/+N4J+Ol1Z+W91J89vREvbz+MVUsuwSur9uM/nnkHb378Ykyo9b/Wex99C219aUysjWJ/RxwvLbkAALBq00Hc9tu3AQA/WDgbHztrMl5ddwCff2I9vnf26bhm/tSsY33/929ja0sPvrloJj75y7fwh8sXumaxxWDJ3ctQFwnj1SUXDWi/0cQPf7cWL7zTCgBYdXV2v/rX/+9l7O+P47Lp4/HQJ53nvHzVPtz5zCZURzW8s+SyvOf49fNb8Iu/7QEAvKexEtfPOxH3PL8FGxYvwqd/+AoWnToBb+5ux+4j/VgwqR7bDvbgo9Mn464rZ2DxnS/i7JPq8fqudvzqA/Nx4XvHFX1ta7Ydwk2/slSAbddfjmjImqGvXL0f/277su47/0x8ePYJYp8ldy3D1adNQUd/Cm/v78p6lg/9cROe723BupsWYW9zNxY/8Df84sJ5uGTGeN82rNx2CPG0gXX7u/DbN/chpZv4wqxT8blLphd9HVnHXNOErzy1ET+/cB4unTEeqze34pbfrMXzV56HPW39+Nel67DiIxcUVAretceJM8bVYt6J9Xjk73swqSKGvy/5gO/23//1GuzvsAImptRX4Of2e//nv+/BN+1cnSsmT8SfNx4EAPzg/da7N1IIDEmR4FpoVzyT15DwyCG+rkdIJd8Ch7Juy7XysVVhdCcy6E/pWYZEzPBMVnRme1OHJWnkyhKWkcgY4mWvjFj/W9qt/7VmcvpIsvNICiVbtvWmMLYqIma/g6khlsyYZbE+xUAgO5R9fSQ5yl1khDPcAGMMRP7yI+BmvlFNRUjKCO9J6qiOaqiy+1pFWEXYLj2S0k0YJsO46giAgTvb5RyVRNpAZzwNhchTa8tTIsUwEdIoK8mVgycjAnCitvL0lXue24KMwbDw5AY0VIbREU8POY+En4+3TygQA4za4v6e9r605CPJfS2m7SMB3CwkXiZRW4EhKRKcHssRIH7gLxDXbUOq4hok5NBLPgjwztBYHcGuI/3oS+mQ536mVPnXZE5HKhT+29RpzWCKie5KZgzEbEPCB5ZcA791bhOaqiCaJ2qL5xDwyJJ4DkdnW18K751QLQzJQKPRdMMqVjcca8ePJHKtWsjB70NWmKxUBoPXp8oFeUCJhhRE7Hvcl9KR1k3UREOoCFv7x0IqIpqCtG4KJ/k4e9I0WGc7YIW0//vTGxHVVLz/lLHie5e8ay+vEPaJBOQ40icZEhG15d9H97T1Y68d8tzUEUdtRdhaJ2eIznYebpzwhG7z9UiA4gZxbkja+lJSZnv+Eil+CY+JtCFkPjmQYKBJkUNF4CMpElzT7CpQKI93CoeRuA1JSqxBwURndAxJ1PVZnFteHY0xqURKIUZivUjFMRJTYiR8lcTcL51uckai5Iza4rNYHlnSl2M22NaXxtiqCMKckQwwP4bfx3JhJL/6+x586pG3Cm7nLXbpRa5aW/L9Gci6MdGQipBmjTq8tlZNVBNOdG5IUroh+iBnJAONdvIyktbuJNr60znDf3V7shQWSa7+4b+NVdyQ5I/aWrntsPh7fVMXamMaKiPakBfp4ufjBkXkkQywaOMR+/6ndFM4yPOthCky2z0lUvrTOirCWlbF7qD6b5mCD9rdBUKAeaIhZySaSq4OIlN7Lm/xgZa/JN6X1uvANgYqbRXDSNIGorZc4DCSPIaE19rylLOQX2xhKPn/PgwnrZvoTmQsacse5AYa/svPk8yUR+Xgjc3d2NjsvzATAPzk5Z1Yu6/DvdhUHkPil7jHMZBy/1ZlXesZ82q/1dGQmDhEwyrCmjUx6BsyI5HLkhjosbPcZdlSNpBiZq8pQi71Psv2vhQaqtyMJFetrZe3HUYDL0mvm6iLhVERLlz6pxAcactt5DWVRLBKrkGcMYbvL9uOjc1drrL9vOpAQWmLsvNIEmnDkiRVxWW8jRGuDlGUISGip4noCiI6bg0PfyG7EsVJW1USI0m7GImJMXa8Pq8AzKWfsdVWx/e+tF5Gwl+wQmt57xeMpPAsLKn7SFvJ3C8d95FwPZu3ib9o1RFNXFe+rH2+oJLLRzLAlyCZ9vfRFIveZCarlM1Q0JfSc/p5OvrT+O9l2/HU2mbXPfcaC8aYk0fiLW5oyIYk/7M1TCb6WzSkCNbX3scNiSZ8YrK0FZfK1oQ1xZdNdicyeH1nm6/xlge1eFpHTyKD/pSRM7OdGwQubQHuZ5kxrOWbedJqOI+01Z/SsWpPOz46dxJq7PewNhayGYn7Op5YvR//+OPXso6RC15pi+d+aFIeSa7IsJ2H+/DAyzvx5JomwUgAiLp8eaUtw05I9CnayH1bbmmr6EsaFhRrGB4E8M8AdhDRvUR0WgnbVHYwpcq7hZISe5MZxKSZX8iHkYyzJSzOSOLC2W47Nj30W67dY5rFr0cyEB9JIu0422O2Zp6rAivg1NqKaApM5hi7VMYAkVWunMsIiTzJlm291oA2tiosBrmBrMUNAPGMc9zBGJInVjfhEz97Y8DnzdmetJFTnuP12tr60khlTCGB5jMWuZztQOEihLrJUFcRRlVEcznbubRVHQ15pC0rGZAbqKqIf8mcjGHi5l+txj//YhXufnZzVvtlRtIVzyBlGyc56U7eJy0xEt4PZUmWvyu1tlEUxsZHtt1ysEc42U+baOVq1VWE7KrW7j69uaUHWw725CwS6UWWs10KSS7kbOdy27uH+sQCXTJyVTgAnOq/iuIuyBhPG4iFNUQ80pbfqpqlRFGGhDG2gjF2HYC5APYCWE5ErxPREiLKnw10DEDOwC3GR1ITczqIpiguCp/STcE8uAyWlJztgB8jkQaVIn0k3fGMmBUWG7XFZ8f5XlIOq/qv89InhZ/CKrVRGVGFlCVHbx3qSWLmN17Cuv18QLUZSbXMSAboI5EMb7HLr7b3pcSg3pPULWf9MPlY+lJ6zgW61uztAGBdd0o3BHP1Pst8a5vLE4jCPhITmkK49YL34IozJgpnO0+ErKsIocIe0GK2tCU72yvCGirCahbzuffFbVizrxMfOG0cHntjH37+2h7X771JXfSj1m7LB2AZWFOwCXnA5dcbURUhscrPQxiSGJeMrYHbb+IgVoOMhvC+CVYYbm1FCJVhNSvgg7PuzgJBNBycAQlpS2IkhcrIv7zdMiQ7D/ehrdcKMPEi1+SQO9tVhVyO9HhaR0XYYpLy/SxbHwkRNQC4EcCnAawD8GNYhmV5SVpWRpAZRUEfSTKDainTNqQpYhbG5QruCxGMxOMj8RoSuWMaPrqyHzgbaagMFzVLT2ZMRG0mIoxDnoE1Y5gIKST2kZf7jGgqYmFNGBAevdWX0rG3rR/9aQOr7QGVU/yxlRFRQHCwPhJ+/mLw8Ku7cYPtEOeDWDEGtxjIxQ69WLPPMaDJjCn6iu6ZqReqksvh53eSoRvWAPSvF0/Hxe8bLxgJL1cztiqCqojz3CO2j4Sz4qqIlrViZiJt4NG/78En5k3GIzfOx+QxMbx7qNd1XrmOF3cmp3QTiYwhosT8ZK6QRo4j3YeR1MScd4sHBnjBjxtWFcFIuLTlfbd45d2O/iINid0mEbVlOlFbvMqDnyHpSWawZm8n6ipC6OhPY39H3GVIanJMKDjMHM52R9pSsrYfSRTrI/lfAK8BqABwJWPsw4yxJxhj/wqgqpQNLAfIHb4YHwmXKwAgpJCgv3yQ4w7MnNKWZ3CQZxfy4JRv3Q4esXVyY5Wo75UPyYwhyjpwiSnfwKrb65FUexzzKd1ARFNQEVKl8F/H2c714F2HLQejw0jC4mUYsI9EMiTFShTNnQn0pXTLuHNDMkyMxDEk7utIZgy809wNIkvSS2YMMYDwbdfu68SMbyzDbtsBC/gUN9SZqAJQyAlumEwMcAAE62vpSkIhq1BmhSRtZTOS7NprzZ1xmAw41w7lbayOuJzHgFX3aQI3JN1ODbTuRAZhm034BaGEVbUoRgJAGD0v+LFCqoKZJ1iGpLEqgsqwmiUbcwmus7+4Ono5o7akoo1+huS1d9ugmwyfOudEaz+TYVJdTIwVfK36XH5Pw3a2azmc7RGPISlXRvIAY2wGY+y7jLGD8g/F1GE52iEP3sX4SOTaP3L4L59t8GgSnrzIB9yqqIZoSMnSveWOKXe0fAPuHru20MnjqopkJAZiYas7KAohrOVepQ6wJRNVETqvLKNFQgoqwqq0fLDjbO+2DTFfgritN42KsIqKsCYGuYH6OeSQzmL35TPyjMHEfRyuPBQ+WHmfzzsHupE2TJw1dQwSGQO6ycT9433stR1HkDZM7DjkLNHstyQtH1CLCf+Va3jxSUJrTxL1lREoCrkSEh1GYh23MqJlGRLOdifb9eMaq3wMSTKDcTXWxMhlSOIZa/aukEsylpes5YxEnhT0+BoS1devxftAWFNwxuQ6/ObmBfjAaeNQYV+HLDny+9cxUGlLd54xkVVWiEtbfoP4huYuhDUFn5g/RXzXWB0Rk0duSHJKW4ZT/dfFSDJO+K+MsmQkAN5HRKKaGBGNIaLbS9SmsoMsLRQyJD0eRqJJme18hl9hr4vulbb4WiDewcGlJedZqlTGtoO9mFQXQ2NVOKdeLx9HN5nwkQD2bK+AjySsKuJaHUZiSVsVUsy+7Gzn94/PuNv6UuJlGmzUluwjKZaR8MEtLclIw8FIGGNi0PXKFNwvdNnMCeI7x5BY2/IVNfnAXBFWsx3xuimKXxYqi859JBxhO8S6oz+NsVVhcQ7AkrY4I4mnDKiKtQKmd8VMHlY+pT4GwBoQ5RUWAWti0VAZhqaQkLYAi9FHNAUhVXFNiuTBP+qTte7HSMI5GAl/3/gs/fzpjWLSo5vM9Vz4BKhTkrb+tqMNLV3+lar5+RJissAQsg11voTEzv406ivCLhbSWBURk0r+PHMFfAhnO2UvbBXzkbbKlZF8hjEm4iMZY50APlNoJyK6nIi2E9FOIvqqz+8XENHbRKQT0cc9v91ARDvsfzdI379ERBuIaDMR/YyI8pfZHAbwDs9rYeVDr9dHojrOdt6BI5qK2lhIhP8m0pYcpCqEirCW5RCU/SK6j67sh22tPThtQjXCmgLG8m/rLLPr3ErvyodeZAxrgOLOYi4RyNKWCP/la62kDRGs0NGfRkd/Gu39KTGgcWfiUKStYhiJYTLhbE7rpngug4n48iKlO0X4vPe8qSOBuooQpo931OAqSdpijGFDs7XkAB+YK8Ja1gqKGcNERVhFSKW81QcAx0fCEVadZ9xg33eRRxJySrj3pXRUhlUQESrD7hUzmzriiIYU4dNrrI6gI+4kGzLG0JfSUW1nzbsMic1IVEny5ddktS87gANwfJPZ0pZ/bhLgTEw4uMGU/UqCkUiG5PbfrcV9f9mRdVzAmQw6znZTSIf5fCTddsVvIsL0cdbzb6yOiGcwhktbOQyAvB6JKyExZaDSziPhCGtK2a5HopBU0McevLPrgUuwt/kJgA8CmAHgWiKa4dlsPywH/u89+9YDuAvA2QAWALiLiMbYP3+CMTYbwCwAjQCuLvIaBg0+0IytCls5AnkGup6kLnRvwK61pTuhsYD1oC3mYUtbkgPSL0TRLxojoik525HSDew+0o/TJlYLmSBfhFfSx5B412L3QrejtriMJ6Qt3YrKiflIW2nddC3puvtIH9p604KRANm1yYpBYoA+kva+lLiPLkOSMdHRn8Yz65oHndgoy2zeXJKWrgROqI25rld2tjd1JMSAlpeR2JFPxawbY5jMNaDypE8AaKi02jF36hjcdO5JmD+t3mEkaafeWyysumTOps44Jo+pEDW+GqsjYMwZjONpA4bJUB3VUBHWspJwQxpZz9knaiusOXkkSY+z3TKezrVEQv6smfsEvbP0So8/z1qTxfaRSNJWMmNi68Ge7JuJbGlLl+6vIqSt7DZ1JTIidPnU8ZaTXZa2GgpIW4Zp+UgUKWrLNK3qGFb4r+PfDHmMzUigWEOyDMCTRHQxEX0AwFIALxXYZwGAnYyx3YyxNIDHAVwlb8AY28sY24jsStmXAVjOGOuw2c9yAJfb+/AnrMEyZiW/Y5yR8PDcXKwkmTGs+kXSrElTFaEFO4xEQVXUkbDiaSf0tiaqCT8Ch9wpMtIxdJP5aqG7DvdDNxlOm1BT1JKkPKFvQIzENBFSyd9Holk+koRdVDCR1oW80tKdENe660ifJW1Vy4ZEGXgeyQB9JAclzT7jkbae39iCLzyxAav3dg6oDRzywO4dFA50JXBCXVT0I8AdrbNeyoZ3GImavbCVvSStxRTyG5KM6WUkzivPB7FYWMU3rpyByogmfCQd/Rkx+w+pissoNnUkMGVMLOs43Pg5ZYJCqIi4BYPepG77SBRfRhKSGEnK42yX2QgAmz35GBLDMUoyeL5MXIow5JMWbgQZY8iYJrYf6vUdjL2Z7RnDFNGGIiHRZxLSI7X/wvc2YsbEGjRUhkWmPmckufq+YUtbKpF457kxk6O2QnaGfblKW/8OYCWAzwL4FwB/AfCVAvtMAtAkfW62vysGefclomUADgPoBfBUkcccNDKCkVgPPZefxFtnC7BeXOFsl2ZdVRFNxLBznRMAJtRGXVIA4DUkNiPhGdE+s59t9sJS75tY7ST55WEkfEbv9ZHkYiSGXRdJUxQhzbijtqxIH65HxzOGoPAtXUmcNtGS3N491IeOuJuRyPerWAyUkciGJKXLhsQUEs4Tq5t89y0E2ZfgvectXQmcUBcTjlXA8ZHohokNTV2IaJbfiYdFV0W07KV2DdP2XWgFExINj48kJA2u/JnIiGiW4drX3o/JtrEIa+7qDE2dcUyprxCfuWF0DIlTAZszbRk8VNY3aktTRPSgl5FkG5Jc4b/WccNeaUtUtdbtdjr3jr/TvG8nMyb2tffDC29CYsYuFQQ4PhK/yKuueEZk5V8+ayJe+Nz50FQFk8fEoCmE8XZgAjcAyYyB37yx11liW3a224aKG8RK2ZBoViBDWTISxpjJGHuQMfZxxtjHGGMPMcYKvbF+ta2Lvbq8+zLGLgMwEUAEgG8BfyK6hYjWENGaI0eOFHlaf/CH6xgS/wiPXk8JecCapfCOJTsUq6POuuhxu/AaYK1ydqgn5ZJWXNKWxEgAf9/HttZehDUF0xoqJUZSWNriUVtAbkZyuDcpfB+WRKEgFlIlH4k1yHGj1BXPgDFHRjnQlUBDZRgnNVTihXcOgjGgURrQvEUui0FygIykVVryN62bUtSWIYzSn99pEVF1A4Hs/PYWV+xJ6jihLoaQqohlbbm0lTEYNjZ3YdakWjRUhoUEWBHRfIs2hlQFFRErUbC1O5lz8bJsH4nMSLINCR+Q9rb3C2NhPROrNA9PdOUrfgJO/hM3JD3ShIr3a5eGr1rOdpe0JTESp0S8m5HU+BiSfFFbIdU9jHCj/eArO/GFJ9a7jL536VzAeo+yji3qujnhv9w3ks/Z3p3IiGcu45/OnIQXPnc+Gqui9vmttv9tRxu+/qfNWLW73Tqm5Gzn3YFHslVFnaitsB2GXJbVf4loOhE9RURbiGg3/1dgt2YAU6TPkwG0FNmugvsyxpIAnoVHLpN+f5gxNo8xNq+xsbHI0/qDv6S8I3hj0Tm8JeQBa4bgZSQRTUV11GEkcYmRjK+JIq2bIt8C8DAS+29O//0GkK0HezB9XBU0VRHO1XwDrHC2a7K0lc1IOvrTuPC/X8Ejf9trXZs9E5NlupRuIhJSxUyUSzR81prWTdTGwphxQg0Odifx/pMb8KEznMWNQtrgfCQi96AIRtLa4/hp3FFbptg/mTHx3IZiu6sD2b8lG8SDdhTQCXXWLJ9PSuTM9sO9KUwZE0NNLOQsqxpSxSAu2qw7suK21l6c972VeHJNs297snwk0t/cuMuQJyjcWIgCiYYpQn95xBYgMRL7WfO+UC2VqJcXSAvbs2ZXiRTdmSAVz0hySFu6VY7eu04Lb8uKrYfx/MYWMRDXV4aFj0Rm+Nt8/CRZjES6v6L6r2cQT+nWBMXbfsB6HqeOrxbGiEuI/B7yMHnDhM1InPGAB4yMq46KZ2QFMrjLKo0EipW2HoVVb0sHcBGAXwP4TYF9VgOYTkQnEVEYwGJYA38xWJB0a+QAACAASURBVAZgkR1mPAbAIgDLiKiKiCYCABFpAP4RwLYijzlo8NkSn9HkGqycRa0kQ6JI4b+SE7AqognDIzvb+Qsnx957s54B98vtxfbWXpE1W6hKqnw90bAsbWUzkmfWHUA8bYj1r3nnr45qYhaaylhRWzFhSHgtLWfQqqsI4e4rZ+KvX74Qv//MOUIfBrKLXBaDeNoQ4ZNDYSQp3UQibWBMRQiT6mJYtbtjQO0APD4SqS183fRJddbz5WzAqbXF0J8yUBHRXAMOl2O8frKwpqIyrKHNDhzwZpZz6B4fCY+MA/ylLdmvwBmJXN6fJ7pOlhhJNGRNjPJJW7IhCalk+Q5dOVFOYl/EZ1LQ42NIcof/mln+EQCojlj7K2Sdr7mThzFXoKM/bflHpONt9WMkPPxXqrXFDUguRuLUCcsdnyRC3+19uWS560i/fUxTVP/lhsoxJBGHkWi2/6kcpS0AMcbYXwAQY2wfY+xu5JCUOBhjOoA7YBmFrQCeZIxtJqJ7iOjDAEBE84moGVbk1UNEtNnetwPAt2AZo9UA7rG/qwTwLBFtBLABlp/kZwO64kGAD+ScaeQyJH4+Ek11nIryrKsqErKS0gwri7hCYiQAcEjyk/glJHJG4leH6XBvClP5IFBgASD5emKh3IyEMYYnVu8H4EgYmt35qyV/T1rS7wHgsH0dsoO5LhZCbUUIJzZUZrUl7HHsFoOkNNsr1kfCX/q0brqylfkCX5PqYq5nUCxy+UhauqxjTax1M5KKsGoPbFY/qIpoLkbLHcTeXKKQSsLIKORUMvDCm0cCOIZBNu4cEZchsdrKJaK0LjOSCtd+jdURwUi4ds8TTQFL/uLNCKmKVczUJyFRjtqSjURXLh+Jz/PmjM2LKfUxfOXy9+LfL7dqzu62Z/tT6ytE+Ra3tOXHSNxLFnCZEchtSPySKb0QxtqTp+IwEqdECne2y+8Wr6EWUrNLzY8Eil0hMWmXkN9BRHcAOACg4ALOjLEXALzg+e4b0t+rYclWfvs+AuARz3eHAMwvss3DBt7huQyRy9/g5yMJSTMv2UfCj9WfMmz91JqtCEYiDWKuF870+Eg8gy7XescWuW4D4J9H4mUk65u68K6dbc0NSUjhjCTk+EgyVkIir3DMS9nLeryfVsyRy0eyanc7vvviNjx+yzlZKwImMgaqIhpCqn8RPy9ae5KYVBfD/o440obhyiNJZAxEwyrG1USwpcU/BDQf5Bwg+Z63dCWgKiQWihorLdAUUhUhf1SEVZcvgBsLb4HDsKrgrBPHoDepwzSZGOC9MAx3iRTAGmwSmSIYyRg+GVHFedv6rIRC76A4VspuT4kJkyNx1sSsKsO9KR1hVXH5DuV7FVIJROQyEhnDRDydLQ15F1Vz3R8fRkJEuP3CU4TfgQ/SJ9pG0WIl1rYnNlRgX3vclRdmmJbh4JFtKZvNhgr4SLgjvy6PIdE8deZ40Mdum5GYDLaBcBjJkd4Uwvaz4ME3Yc0ab8qVkXweVp2tfwNwFoDrAdyQd49jCNwQCGkrx+yeJxjKA4EVL2/NXlISI+HGpieZQVc8I9aMGFcdAZFb2vJjJI6W7X6R+MvMB6qwz+zOC8488jGS/9tyCCGVMHdqnfB78JmYnI1v+UgUjK+1zs8z2GVGko/i8xfBi1V7OrC+qUsYJhncx+RdZMsPjDG0didxYoM1eLikLYmRjK+JDoqRyP4z+TpauhOYUBMVLI7fj2jIcjzzvlMZ1lzVowUj8YTKhjUFV8+bgp9/ah5ObKhEU0fCN/fFCv91v+ZhOxiCswUZPB+hvjIs8i7kYpqpjJFlyPn18ACBlJiYKOIcNTFNGEUrasuzBLUnZFdebtcvq523NVf4r58h4eC17njf5Oy9sz8j2jR7slXIY+tBR97ixo5PhJIZQ5QKAqSoLft9fXt/J5a+tT9n+2V4pS0etHGgK4F4WodumllFG/mKkUQkGA1P9iy7MvJ2YuEnGGN9jLFmxtgSO3LrzRFoX1mAdy7OInJLWxkQAVVhNyPh6wy4orbsl/RgdxK6yYTGH1IVNFRGXIOY7tHHAeeF9/oTHOd22LVdXmd7OlvaimiqSzZo602hoTKCyWMqxOp6so+Ez4y5tDW2MgJNIeyxZ1SyjDImLyMhX/bEr+uAT+kKvpYKX1kvH/jaGHzwSBvM5WxP2APl+JoI+tOGMJC7j/ThAz94JaumlBd9OfJIWuwcEo7zThmLC9/baC/oRaIYaKXXRxLOljBlOQWwJJtExhD+KBmGyXylLT82AjgTFDlPRJ6M5BqkGwsxkqhTHDKscWnLh5HYRi8aUpHIGLjqJ3/Hr1/fC8DPkPhHbVnSXx5DYhtxPtvnMp2VnW+1ac4Uy5BsbukW+3GG7sioVh5KLh/JN5/djLue3SxUgnxM3CttyWHdu4/0wzQd/5YpOdt5PTMnj6RMw3/tMN+zyBsCcRyBs4Bq4Wz3H6x6kjqqwppYchNwBlvdZK6oLW6U+Ay7TpqlT6iNuKQtFyMRUVuKq20cXud2MT4SLm1xJyf/Oym9pJ1xK3xRNgKCkdiGRC4Bo9gyzh571icPXHWx/E5Hfpydh/vwk5d3gjEmBqmDXdksIZlxKqAWYiQ8h0QYEk8eSSLtMBLA8VW9e6gXu4/053Rqc8Tz+Eh4xBYAzJ5Sh18tWSBm5zxKrzKiugZMHrRgeAZdlyGxJSg/eUs3TJezHbAiCRt8/COAY0gmSz4Qx9luioRTLxqrI+hN6UjarE4ha1LADUltzIngypWQaC3cZLU1GlKxtz2ODU1d+OXf9ohjuNuqIm2YWUm5XPrLhcqIJpbdjYYUMRh3SWVeJo2xKhBsOuDIm/y9l/1xumS0NKn679aDPdjQ3I20boow4nyMxCttyUm2u9v6XdV/HWd7UhhFOfzXW49rJFCstLUOwJ+I6JNE9FH+r5QNKyfwhxsNqdAUyjlYNXcmRKfkkBMC+WAuO6O5k7S+0ulkE2qiOaWtjO5mJF5pS5RlH4CPhK9qKA8QvLIql0u6E2mMqQi7ZClN8pH0pXTBbPhxxtdGhZGqDGuotAeSQjMzfk1L39qP/162HZ3xjDAkfsX0+KJc0RyauYzWHmt/2ZDIUXXJjIloSBXS0yFpLQ0AIrrn7f2dvlJSX8oQ90WuPXWwO+GKXPJeM68lVRl2nO0838J7LC8rmGrLdH4Odyv8121IYiFV5H5ktUUwkoqs79K6iVQORsIZNWd8Ec2q0+VIW85KjKJEisdHEnb1P0WE33K50JtHItrlU9TSz9jJ4ANwdTSEervtHf2OIQmrCmZNqsnBSKzteQVnbgS4vdZN5kpoXd/UBSJ3NKcXWdJWysCJDRVQyJpQCWe74uSRHO5NCV8kv96wZid7lqkhqQfQDitS60r734dK1ahyA38omkqIhdScjGRzSzdmTap1fccHFV2SUOSquXwWKTOS8TXRnIwk42EkWdJWbwqxkCr07YhPJVUvEvZaJDLp9FZgzcdIeJkPLnnxc/L1KABrZs1X4qst0tnOZ/8tXQkREeRnSOJc2vLIcX5o7baOM1X4SAzXwlZWOX2HkRzuSYnfAGuwWdfUhY/+9HW8vT97nff+lC4MJTf6acMyVjU5BhJNkrYqJEbCJSDA6YP8/7BkHHgGOg9nleHnI/nWR2bhy5e917ctfIIi54mEshhJto9EzuNJSnk9fD34mqgm2FWYMxJP1JbMsqIhVYSUc/hJW0B28Euu8F8ZfACujmjCQHXFM64w5Jkn1GDH4T7X6p9yO5J2lBdvN9nhucmMgWfWHcD8aVZ5wE0HulEd0bKYoQw/aauuIozJYyqww34PeKl6gzGkdANd8UwWI+FRWyPNSIqK2mKMLSl1Q8oZnIJrioJISPV1trf3pXCwO4lZJ3gMiaqIY6TssERrDQirMzbbJbnHyNJWTRRd8Yz9Qqr+me05wn+t2lXOsSJFJCQmM6Z4ycV+0ip10ZBqlXioCLvayWdinF3xdcD5vuNlQxJSURlW0aE4i2H5ISQ52/maHC1dCcFI/HwkXNryYyQ/XP4utrf24KFPWsvmtHYnoJCTB5E2zOyoLU3JkrZShmNI+IDtl/nOB4C2PkdvlycQvtesKoKBVoY1UcKB5wQAyAohlwfdirCGsVXhnIzE6yOZP63etx0A8J7GSlw6YzwumO4k8cqMJJePhPvXkrrhMjbceI6pCAuj4lsixchmJIBloE4aW4WtB3t8o7YAzhSc33JFbclorOGMxBrgecQfn8RoKmHWCbUwTIbtrb2YPaVOGCy3j8QdaqwqhH3t/ehOZHDN/KnYdKAHiYzhehf8wItp8vMn0lZV3+pIhZC/OSMxTEfq5czZ5WwfBWmrKENCRI/Cp7wJY+ymYW9RGYIvlWuVuFZcJTk4NtuhojMn1bi+l6UtWbut9vhI5Jk+l0AO9SRxYkOlu4w8ZyQ5wn/b+ty1q/jLVij8N+aJxJFXqathGrriadRVhFxsIiSuJSTODTiDgCzlcJbES2nnAne29yQzgpXtONwnNOOWbrchydiz/ZjNSLyy45u72101kw52J9FYHRHXK5dH5yVSYvZ6MZVhFYd63JFIHf1p1NgvsV9Npf6ULp5l2jP45xrcrPBfa5tKaebKw2QB57nL+RYyJo+pyPKRMMayVkgshMqIhp9/yr1WnSwh8YRTL+Qll5O6w0jOmz4WP148B2dMrhUyV0iUSJGitnTmMrQ8MmxaQyWumTcZP/7LjixJNFcgSdowhQ8yF/hMnm8XtouFysUjubqwqaXbMiT2BNIVtSXV2gIAlUistthQGcaJDRXY1tqb1z8COP4VEf6bNlBXEUZ1VBP5LPLiWXyCw6V0OfxXLeOijc8D+LP97y8AagD05d3jGIIuzVKiORjJJltLnTnRy0jc0hZ/4BVh1Qrz7bGWPJVlD2c2bA9YPtEtDiPJ9pHIpS/EsrkFnO2yox1wXtJkxopcsiLLQi5GwmdiVULa4ozELW1FQwoUxVrXIl8sPW9vxnCvELjRroo7rjqC1u6ka7bl1AnzZyQHOhOu4nytPUlMqI2JtstRVrKzHbCew6Fej48knhazQb/yNP0pQ8iU3pUxcxsSZ6CvjKhCKrT0bndQhVyTSsaU+gqx4BSHkGTzSCrFQEyGbEbia0iksibJjCH6T0hVcNWcSba/xBnssvJIPIyEG6KTxlbihvdPwxtfuzjn+iLewpWFnO2ALG05MmLacBISw3ZBxeqoJkrK8z4gG5KMJ09HU0i8BzWxEE4aW+naJxecEGsn/LcirNqLhlkTNCuz3dqeS7T8Ovj1hm22V5YrJDLGnpb+/Q7AJ2CtB3JcQPaR+NWgAoDNB3owpT6Wpf+79GXdEA+cyCnBXlcRdkV6cQmAO6rdUVuehEQzW9pqlKQtxabthZztuRhJSjedhKqKsMsQ8FkUZ1c8jyAScktbfCZ68rhKsRZDLoSEIekV7djQZBnp2VPqkDGYazU+7uCP+jAS3TDR2pNEPG2IQb+1O4mJNVEr9l5TREY+YN3vlG6K2fC4mojIHub3r6PPMSTeew9Yhqk6ollLyXoZSR5pi6NS0uy549Q6V/5jnZCnarTXRzJQyIwklyObS6NJcQ+zt3EKOPqUSPFko3NDNG1sJYjIN3eFz/K7PdW404bpqnLsh0YvI9E8jESzEiPHVUdE+G5W+K9u5ZGEZEaikti+VjIk3kABL4h4AIITtVUZcQdFKFJUG18qOttHYkVtlSsj8WI6gKnD2ZByhuhcipIz6W1zS3eWfwRwzzTSdrIeR7UwJP7Ghw9+7lpbnoREyUAYJrOXUM2OHMvnI+noT/uGVgLWwCBn5vr5SPh1tPW7pa2JtrTFjdR3P3oGHrx+bs52AE4lgB2H+xANKThzyhgxQM6ebN1f2eHOja2fj6S1x2EvnHm0dieF5BZRFfRJs1leykIuoCmkLRF0kBaOf79SLnxBKLmiQSFpS2YMFSEr073CXvUupLgZiZgxe44VtouD+lWNHiojcU+G/P0P3HAkbGe7n0O+Ugr/9ZZIyfKRcEbiU0aHg7N4r1M+rZuiZEguOFFb/obEmSSFXGvtAI4hSaRN6AZzLRamEolVQGtjIUzjjKSAIeHnFIYkZVUElxN5NUnaau22lIwGT3TmaOWRFOsj6YXbR9IKa42S4wIZOxZfUayZkXed7CO9Kextj+PqeVOy9s16CaUOXhXVgG63o927D1BgPRJJXunoT8Nk2TWUIiE1LyOxqvCOdX0nMxJuOMdUWpqtQlbJhiwfSa9H2uKGRHLkF0pHmlgbRV9Kx3MbWnDKuCpMGuPOvQCsnIwz7WmMvJaKl5HIUUy9SR2qQuhN6aJdIU1xFVnkAwD3P/HsdmZHyQBWZBq/BnkgfH5jC7Ye7LELL6ouFihXNPCDnM3NpazaWMjFSPikIpND2pITX8WSr4bDpIcCl7M9h2wknO02I6nyCaiIZeWRuBNtvVFbAMRA7AfBSP7/9s48XLKyvvPf31mq6u739r5v0DTdNILQNCqL4IINo6LGBXUiRh1GR2aixicSTUQxkxkzEzPjE6MSw4zG3RgiTnBBYxiXMbLIKmAjNtDQTXfTt5d7b1fdWt75433fc95z6pxT+6lTt3+f57nPrTpVp+qts7y/97eHGs0142zXvgW9CNI5KeFeJjrZFoiO2poP+0gs8sqsTLRg2gL87qBCCMypABJTkOh+JACw71gRi0fz3nMz/Ne20m+122zUVrI9YoFTMbJXC66Fw7NBLeB9X78HOcfCS7ctr9vXs3HXanUX+JgX0RKtkWgnf3Rme1DYAPU5JJqcHd0ASP42WeTRzLqWn+9PDNOGRmJZhIkhF9Oq9zZg+kjmA/sWXDuQiNYMb3nBenz7vqdx396juODUJV4Sn0XwND5TI9FO+EKERvKUIUiOFcveMdCaUs72TVsW+SYSPeEtG8ujVKnhWLHiCYVplUcCBCPm/um+ffjOA/vl8cg5noYANOMjUcfRmHzHC67nSwD8a8CsSWViJr5qZUCbwzrXSFTRxqrwGpeF0YJEaiQ1LB6J0Eh0yRWnXiMJL7L09b2xCUFyLCRImgn/XTk+BNsib0Vf52x3/KoN+nqLNG1Vg3k6+lgPubLZ1KYlI7AIsXk7JvqakQUhUaeR2EReO9+Dx0tee169r/wdwVLzadGUaYuIXk1EE8bzSSJ6Ve+GlS3MWPFw+O/f/Pgx/Hj3IdzwyjMi7f+maasUsi/riSOskYRjyoNRW/6qKO9YuP8pP2HKFyTBz8u78e1rD83Mo1oTdclynkZSruHonC7xkAuMV980I6qCrQ4/NW/iFeOFOv9LEnnHxl+/+RysnCjg+ZsWe2XXF4/mMTnsYjTvBEKAi0bfjrxre+2Oi+Vq4H3HixXPQamDAHKO5Zm8RvOON+Hr1bAWyM/OlDwBVakJz/lpCnGzS6M2belj3qxpy2xLe/baSWxbOR5YiADxQsm16hcW3fKR6BByTyOJ+B15TyORvsBoH4nOI6G68N/w5H/6ijFsXTke2XxLoxcwURpJUokUQOYyff3fPx+v2yFrxuqS9JWwaSvv1mkk2t9RnA/W2gLg+TC0sFk8msc33vmCSGtFGG3a0sEDYR+JY2gkh2fnA1pOsERKMEcnDZqt/nu9EOJm/UQIcYSIrgfwj70ZVraQF4vSSBw7kAB1+yMHcebqCVy1M9plZJqpwjehvhHMfhxAfUy5GRykV8FDro3X71iLr97xBN730i1YMVHwBclY8z4SHU67sk6Q+HkBnkaiLlz930zEGs07OHC8hLPWTHgFEQHgP1x6SsMs4zBrpobxs+teBCLCj3fL7pa6ON0pS0cC5b111rMs2igDIf7gG/fimWNFbDDGcbxY8Tpb6lLupiAZK7ierV0LvoKxyo46fuZEqOP+Z+erWDSSCyRWNjJtacfwiFGj7eOvfQ4AmcwG+OddLy7C5qVw1A8QDBLphJyh/YYXQ5qAaSsmadGstaV7ZgghQCTNgLlh/3PfcN46vOG8ZDesbRHGCk69IGlCIwGAc9dPBX6jjEpLMG2V/YVGQZUQKleFVwUb8BcFps/R/J4kXEcK17mS9vvJcHlHhfOazvZnZ0o4demoP36dR6LCf1NWSJp2tke9r1khNPDIwmzyEMioLX/1+cThOZyyNF79NjPbw2aBOGd7OKY8oJGobbZF+HcXbUK1JnDTT2UtokPH65tIAfHltgG/yrCeXL19jKzh6bl5VabdUuNVGokxQW1fPYErzlyBr1zzvMBq8MqzV2PX9pWR352E9kN4/TuUcDxr7STu33vUW20fVqGWU8M5b1X8490H8YvfHsYvfnvYMxvOlMreb/UK3dm+j8Qs/a8FiB+JVMN8VG9w47wUKzXs2LAI33zXC7Br+4pACRA/0ipaM9MT0UiEX8EPvAiF/4YmSjPxVeOvrrtk2krQSFybYJEUqHEaSdjZDgTzYxppEVGMF9xAYqjuEdIo/DdM3rGUjyRs2nJVn5JgiaOCa3uLEFMjsSMESbPoOnNaIxnOyZp1+n42ne1HQq17x4dcnLZ8FFtWjKk8knQ1kmaP9p1E9AkiOoWINhHRXwK4q5cDyxLlas0rSVFwfYduqVLF00dPYF1CZInv76iPeGlk2orykejHRIR1i4dxxZkr8ZVfPIFqTeCxQ7OYGHK9PASNrpsVhbb/JmkkR+eCF62nkRgmky+943z89ZvPjSxN3gnad6NV/LPWTGJ2vopHD8g8E21mWjqW94SfjjLb8+wctq6UCaLHixXsP1bE1LDr/bagRuKPWwuQsAM5XOLC1EiKKv/k3PVTKKjIq1YSEgFE+pJ830fQ2R6eKM3EV298nmmrM0Hi2BYs0mXTRaS2QaTLB0kfSdR7zlk/hWsu3oRz10/V58c04SCPYmLIDfhIGvmj4tA+kjrTlrouZooVlCo1WCQn9CHX9jQVN0KQNAr3jcJVpi2zMRjghyrrVrsAIATqkoO//94X4tIty2SJlIy22v2PAOYBfA3A1wGcAPDuXg0qa1Sqvh1Uq7SAjAoSwm+ME4W5ogzH4HumrXDUVp1pq97Zri/YS7Ysw/FiBb89NIuH9x/D6SvG6iKjkpzt+48WUXDrGxWFNRJTkHgl742wx14Vhx7OObjw1CU4f6Ms63H2Ohm5de+TMknx0EwJo3lHmRv8yUuvfk9f4QuSg8dLgVIVOSNE1yyo55u2VEjrvDTXLA+ZDMM+EjM6Lehs91ssR6GvrahIJ1OjBWQGOFAftWUmvmqqXvhvZz4S/X1ae4v7HUM5W5kBozWSgmvjg1dsxXDO8QtbegJStKeRDDleLxegcc5OHGHTltaYtCA5rgSJLkZZcG3MKE0oWCLFj7prFc+05flIVHdJdd2ZznYgvoq2WSE4LZo62kKIWSHEdUKIHervg0KI2cZ7LgzKRkhlwbFVp7QannhWOpc3LEkSJP6KMqyRNIra0vbwilHBVU98epG5XZVkuf+pI/j1/uPeCtwkydm+71gRqyaG6gSBqZEcOVEOCLtVk0MYztlt3fjt8MV3nI/XnyedlRsXj2Cs4OCevVqQzHsOWVNIv/3CjfL9S0eQsy0cK5ZxcKYUiIIJnosI05ZxDOartUBAAlHQH6H7mGhMH0kjjURru1HaXLPOdvN9+48WcfMv93pCpVMfif6+40qQxPl68o6N2VJFdRFMDrAIm+zi8lMaMTHk4ugJWZfuf/30t16ycMsaiWHa0l0aAf8ePVYsy/Iwrh+q7Zm2GvhImsUzbZVCGonSxm2LAucyLqRY1+NKk2ajtm4joknj+RQRfa93w8oWlWot0HAHkGq+ruG0blETpq1KzVvRaLSPJOxsD5chl6XAgzZwvTI5Zekoco6F7z6wH7PzVZy+oj5yLMnZvu9IdHlzr7RKueYVbNS8+fx1uPU/XZSaIDGxLMJZayZ9jeR4ybMh63OzcckI3nT+epy2fBQ7NyzyHKYHjfcCSYIkeK613X9yOIeCa2EkZ2PYtQP+iOJ8cBXu2oRypfmijQAwmq+ffF0ruICIc7bnPD+GwDfv3ov3fu3eyImuXcxQ6SSNxMvFidBITKLyY3JtCLyJIekj+cFDz+Cj3/4V7txzGEC9xtYI07RlanDjdRqJfG0oZ3tO/qSorVbQpq0TZe0jCWkkVlgjiakmneFaW0uEEF7NbCHENJro2b5QKBvZq3657BoePzyH4ZydGKLoCYCawHwlWPDusjOW4wO7Tg9EXwDwWmfqEhyVWs2InNEaCXmfv3XFGP754QMAgNMjNZJ4H8n+o8U6Rzsgb4icY6morfnARVtw7cREsV5z1toJPLz/OIrlqqx2HMruPWPVOFZMFPD9974QW1aMBQRJQCMxk0PzUaatcCSS7F65dCwPx7YCN2uxEiwzk1MJboAftdXItDUcZdpSr1UNpzQQNCsCvvmqUqt5BSZnSnKi69RHAiiNpJiskRRcy/NPNYrU88KVjd/VjkYyXpAaiU4+1ZGLbWkkOgrLEGhaI5kpVQILwQ2LR7wOi1F5JBNDrfsKtWlLayQjIR+JbQXPZVw7hn6UkW/2aNeIyIvFI6INiKgGvFApG6uUfEAjmcO6RcOJ/gGz81mxHCyRMjmcw7suOSVQZ0sjV7QRGkkt6CMBgDNWT6BcFSACTls+WvdZcRpJtSbwzPFSnaNdk3dkpeOjJ8qJ7XHTRpf33v3MTKBsvp74zwiVqhkruNh35ARKlVogLj9OI/Gc7WbUlproFo3ksHRMtsedN1bTugKx99lG3SS/c2SyaWskwtluh7RTz7QVDv81QnS1nV9PSN3QHF3bN+XEaiSuv0qPqo1lEtZImsn9iGJiyMXcfBV7VCdOHXzRriAJhw77PhLd1kG+du76KW8hEeVsT+q5E4c2h2ofiV5YLPFMW5YXtQXE+0gyW0YewIcA/ISIblfPLwZwTW+GlD3M7FV9g5Qq0rR16rL6idtEr7xmS9LOx2KglQAAIABJREFUntSLI7Cf4aytqFh1i+p9JIBcgQNylRRlZ48L/z14vBSZjKgpuDb2HS1CiHrzWz/ZqMKtdx84jum5snej6ZWbbiikkaW4jwfeAwQnGzPSTVey1aVSThgayXWXnw7HIrzna/d4k6BZgVgT6SOJmSi11hEd/huT2V6XkBis6QbAc453SyOZ8Xwk0UJC9q0JNjeLQ//mclWgVhPKD9iOs11O2LpCr668246zvVStoVwJmrainO1AsKdLIPyX2jdtOZaF+arworaGDFMtIMvSm6kHcT4Suw8dEpstkfJdItoBKTzuAfAtyMitk4JKzb+49OQyN1/Fk9Mn8OKt9WVRTLQJQnfAi5osIvezLW9lWa0J2La0j+rJydSCdOmQKP8IEB+1tS8mGVGTdyyvz8qmpckCM03WK5/UXY9PA/BXbFtXjuOn170IqyeDprqxguNVZI0TJDqCLu9YnoboqHyHoopEyjs2Ljh1iXrNz8z2e96HBYk/+euGZlHoCXQkytkeamwVrgXlfYbjO6/1NdJtH8mBuWAttTAFUyNp5Gz3Sr/U2g7ZBfwJWy8UnvU0ktZ+c94okWKaDUcNjaRkmKY3LxvFeMHBsWIlmJBoa0HS+sIr5xAqKvy34FreAmDbqnH87LoXYdXkUKAFd5wgcayMlpEnondA9iH5A/X3dwA+0rthZQuz54DWSB5/dg7zlZrX+zsOPREcUc1uokI8ozB7l1dqQob+GT0czFWm9gOcsy46gzZOI3l2pn5yNSm4tldmJMpk1i+GcjZWThRw556gIAFQJ0SAYGhvwNlumxqJfE/YJFNwZUhrOM/Btfw8EZ3xPBQSJGbRxqQVstY6kjSScHJjXfivYQILC5JuaCSuY3k+lzhBMuTaXkZ1sxqJKfha1SIAGf4L+H4oT5DEJH/GkTMWiOaxzTu25x8qGaZpyyIvY72bCYnlag2zpUrdokLXnDObnsWVHrJVGXmRYghws2fu9wGcB+BxIcSlAJ4L4GCjnYhoFxE9QkSPEtF1Ea9fTER3E1GFiF4beu1qItqt/q5W24aJ6J+I6GEiepCI/muT4+8IGVESjOT5zUGZELdmqn7iMtETwbRS+ccKzWokvvZRFcLrjqZ9JObcUHBt/Mv7L8HvXbAh8rP0auuJZ+e8XhqAbNIE1OexePupm2ss7wT6r2eBjUtG8Mgz2lyVvPozj3l8+K+88ev7stheQqI5gUZpJEFnOwUSEpNW215CYkTUlu4DbjrbbaPmUvgzpI9ElSKf756PJG9bDUNrzUitRhqJXph94rZf4w2f/Xni5yYRnrAPzbbvbAeUIAnl3WjNIxx1uUOZt8yQ3E5MW1qLnZuvRl4LgBEVNhzfaVTnsqSplDR7tItCiCIAEFFeCPEwgC1JOxCRDeBTAC4HsA3AG4loW+htTwB4K4Avh/ZdBOB6AOcD2AngeiLSy+3/LoQ4HVKYXUBElzf5G9qmEtBI5CF7XOWQxPkXNEQExyIvmqVZ05ZjaCRVVaIl6CMJXkSLR/OBlZGJNrm85tM/w5/d+pC3fVqZexbF+D+00Dx1+WjPEg7bxYwaC5eECaOFhGNRIPpMLw4s8mP2w73rh1wbs6X6jG7X9gvjnfDqfVmB18stCpIo0xYgV6FlI7M9XPnX/AzTR9JdjcT/jCRnu6ahRqLG9M8PH8CvlH+jXWe7idZIoo5REvpamClV6iLiZE+SMo4Vy4HqAxdvXgqLgOVj/hzQmUZCnrN92I25FtR9mBT84rURSFGSNHvm9qo8kn8EcBsRfQvA0w322QngUSHEY0KIeQBfBXCl+QYhxB4hxH0AwnaXlwG4TQhxWIUa3wZglxBiTgjxI7XvPIC7Aaxp8je0TblmZrZr05aMEjEvojhc2/I0kmZNW9I04pdI0f1QvDySFiYHfZMcmikFugsenptHzrFiy7zrFfhpy7LXRcBseNRIkGhH+pLRfOC4eaW3Hcv7rfWmLcuz++cCGonvA9EaSSEkaHTUXaMigo5n2oqvxRVI3IuYcM1SKp5pq9hdH4km1tluXEeNEhJNh/Y7X3gKLtq8BGevnUzYIxqzRbVrU+S5aoacGu9sqVIn0MYKsiDpE4fnsNm4F85cM4Ff/sll2LbKD7l3bPJKyLeKH7WVpJHI/3ERW4C/yExTkDTrbH+1evgRIvoRgAkA322w22oATxrP90JqGM0Qte9q8w1KsL0CwP+M+gAiugYqsmzduuQqoo3QUVOAP1k8cfgEcrbVVMMaxyavgm7zPhLDtKWqD9sWefZ4uwUNwVwdmo2cpmfnMZWgIutJdXOG/CMaHcky5NoNtbzRUKkJjVl62++hEpwAzJDWfMBH4p8fT5DURW0ZdaQSVttrJoeQd6xA+RYTx7aCiXsRk1TO0EjKXvhvfVHBdjEn11jTliE8GiUkmhrD2y7c4PUebxWzptWpy8a86K1WK06bpq2wqXes4OCux6chhPRHmoTDfC2itrQRwL9monwkGs90lqSRGIEMQGu+onZpOWtGCHF743cBAKJmp2ZFZOK+ROQA+AqATwohHov6ACHEjQBuBIAdO3a0JZq/+8B+jBWcQGVSfYMcmilhzVR9aZEoXNvCURW1Ndq0jyTkbFdZreUIH0kjzJtK280BYHquHOsfMffb3KDPej/Qpq0lDfwjgG/aqhMk6pzmHcsTtlE+Eu1XysX4SEpRPhKVZyK7K9a8FW8Uzz9lMe758GV1ZjWNa4RzxlXJNfOVwqatrmgkjqmRxJi2WtFI1G84c/VE20IEkOcn51hwLcLaqSFPkLSc2e4kmLbyrucf2roy+V7YtX0FtrR5vzhq8ThTqsRq2dp0ltS6V78nzQLAvSwFvxeA2c1lDRqbw8x9Lwnt+y/G8xsB7BZC/I8OxteQv7zt19iwZFhFbQUTEgHEriDDmCXFWwn/rRjhv44SJDoQoxXT1pqpYQy5NrauHMMBw9k+PTsf6x8BfI0kSxFbmnWLhmFRY7MW4DvbwxUIdMhszvZNW1GC5EiURmJbmKnIiTrK2R6oaNDAtEVEsUIEQKAtbZy/xQwT1s52XY68W3kkUY9N2vGRXHp65wUyJoZcTA27Ae2kneq/QLxpC5B+tLVTyVGaL3/Oqpa+NzyG+WoNew7N4dIt0cdF3/dJlhA7oJGkQ+c6bzx3ANhMRBuJKAfgKgC3NLnv9wBcpmp6TQG4TG0DEf0ppGntPT0Yc4CpERfTs2VUar6D01TZl483nsSAoD04TmUN4zp+eKnWSMzrO+xsT+KCU5fgnutfim2rxgOmrcNz84mJhmMFB+OF7EVsAXKiWL94pKmx6YkgrJHk1QF1HcO0FeFs90xbIUHhRW3Nq/Bf07RlZppXqt53tYPpbD9yohwZ+We2HtCarM5s70rRRruxRhKI2mqQ2X7qslG88qxVeP2Ozl2ci0dyWLdoJHBc2ulHAqhWxVZYkMhJe8uKsZYWcK3i2haEkD61M1ZPRL5Hm7YmEywJWpBkzkfSDkKIChFdCykAbAA3CSEeJKIbANwphLiFiM4DcDOAKQCvIKKPCiHOEEIcJqKPQQojALhBbVsDmWX/MIC7lVnpr4QQn+vFb5gazmH3gRnVs91fvRLJfgDNquR6dTSSs5teHQZ9JAI51w74RVrxkQDS1DCSd7yOgoDSSBIuyHddcgpec86azEVsaf7qTc/FWL6xPdozbYV72UdoJOGw1YJreTekOTk5UT4SxzRtKUFSkVFUnfRpcQ0z2v6jRayNyF0yS47UJyR2vl5sRiMxhUcjH0XBtfHJNz6343EBwCdefzZG8w7+/u69DccYR/D3haO25LnTLQl6RaBR3Kro72omKkxre2mWku9pl0MhxK0Abg1t+7Dx+A7ERF0JIW4CcFNo215E+096wtRIDtOz84GQSyJCwZFJas2atrze5k2atYB6H4llUWBCpzbmhtGc42XvWkSyPHyCRrJyYiiyoGNWCNfUimP94mG8cee6uioEZtSWZclCmWYILxCy+weq+/rnp+g5243XHa0hSFPTVBtRPBrH9oXZ00dOYOfGRXXvCRYH7X6JlICzPWa1rwUJUXvJhe2io6bMMjft+kii9vUFSW99hfqYjeRsbIhplhdudhWF1prM3jS95qRpl9sOi4ZzXtiueXEVXAsnylUsSziZJl6Z8CYd7Xqfsucjqck2m1b7GgngC7LZUgU1IbWqLBVj7BWubeG/vObMuu1en2v1f+vKsTpHadwq23SAF8tVWKHJM2c4v0vl9irbarT2M1uq4FixEinczXa4+rrRgRXddLbnHCtWQ9U+knzCe3qJGQrccq2tgLYZTkiUn9trQaKvw22rxmNNaJuWjuKLbz8fz9tUv5jQOAvJtLUQmBrJedmhptopJ5dyS852oPnQX7mPX2KjWkNdNnMrPhKNzlOYna96SXRJzvaFjjk5AsC3rr2w7j1xgsQJ+EhkCXlz8gxnmnckSJTQ2n9M1lmKqo2mE18rtVpdy4Bu+Ej070kyWWntrZF/pFdozSGprlkcSaati09biqufv97rztkr9HlqpGlfuHlJ4uv2QjNtDTqLRoI9kTX6Rmna2a41khYESc4J5ZFYBFN2tGP2NjUS7UBOCv9d6OjJI3FydKNDWs0y8uHuiPJ109menEfSCEc1PNp3RAqSuGoKjooONPu26/07Jd/EsdI+olZzOLqF9oW1kyGfZNpaMVHAR6/c3tngmkB/7xkx/pFm6YezvT9nfEAwJ1nTPKBvlGUtaiSd+Eh0rS1NexqJ/P6ZUsWrhnsyayRuyLQVhRmJFNBILD9JMEmQzCtneycaiXa262rNq2L8VrrDXjkkSLoRaKSv4aT8EO1f6pdGogs4tnOsk0xbaaFNaO1k+Js4ffCRsCBJwJxkwxpJwbUCzr0k9L7N9iIB9Co0mEfSsY8k52skus5WlvqMpI0WDEnaQrAQY3DV6ick1uryQLR5ZF5rJB35SKSzXZcQXxajCbuOHFPZMG2Z/cc7QR+jpN+Rz4hG0o72F/B/tViCvlu8ZOsy3HLtBR0nAPtFG1mQZAJTI3EDPhJZzqLZG9QryteKRmKYtipVAduyAlpIO3OD5yMpVb2SLUnhvwsdr0RKkrmmSdNWOJHRNG2VuuAjKddqePpoEYtHcrErfu2ULxsr0W5EbAF+LarB8JF0ZtpKM+LMxLEtPGdN534YPfw0m1uxjyQBc7Vu1ivauXExjikfQzNoVbOVqC2zH4mX2a6GYBHaWmWOGj6S6bl55B0rMaN6oeOtshNNW3HOdj9q68R8ta62lG/akhpJJwmJS0bzePDpYxjNO1g5GW9OdVVmtOkj6ZaZRi+kkgSiGbXVD8aM5mStkuQjGTS0RlJNMbOdBUkCIznbK1tg+kje99LTWvocveJtNWqrJqQQqagOidqc1Y5/BICXFDc7L30kJ7N/BKiP2ooiybRVVc2DTpSrddnmejLSIbidaCSXbVuOm3/5FH7+2LN44WnxJUVcm7xoPE33NJLmhW6/NJK8YyPvWJ37SLoQ5dZP/PDf9L5zsEVvjyEiTI20Hwmi0ZWDWxUkgDSNVGs1r0Mi0FqdLRNfI6mqyr8sSAA/5yOK+DwSfX4EihGmLbN2k/ld7XDJlmUYcm2UqyK2LTIgtea5kCBptS9HHF6By4QaWrZK6uyXRgJIP0k7x9qxLS8ooV+mrW6hF5p/+5PHcP6f/cCrcNDT7+z5Nww4erLtRJC0E/7rJZhVa4Hqv0D7UTgFV94ss6UKDrFG4p3TRI1ERSLZFgXMm2Zr22K5Wmci1A5bfRN3MjkN5Wy8aKvURBqZtubmg5NGmhoJIAVNvk8aCSCz29u9V822AoOM1qieOnIC07NljKRgvh7sI5YCerLtRN1tx9muL+pypeZHbSlB0k7EFiA1rJGcg5lSBc8cLTbs7rjQyTdh2tIaSXgCNXuOnyhX62p06XOuBUmnk+vLz1wJIDoZ0f9O8go1euPsmo9E55Ek/46RnBPbSzwNxofchr1Q4tDneNBNW3rx8MyxEhaP5lKpMsA+kgZoh3snJgK9b7P92uU+vumkqnwkvrO9/bGM5B0cK5Zx4HgxcVI6GdCNyZKKb2pBEjbpeCVQajWZ2R4O/w2btjpc5b5k23L88b/ZipduWxH7Hte2cLwow7qHXFkPrluTYjP+JAD401dtx5pF/avPdt3lp7ddEkZGptWXkR809ELz0EwJ25usR9cpLEgaoGtRdbKyayv8N+AjCeaRdFLKeiRvY8+hWdQEMl2QMQ0si/DD970w0MciTFwkkqmRFMu1Ogez2SjJfN4urm3hHRdtSnyPY5EnuMYKDk6Uq10zbTVTIgWQAq+fPG/T4rb3bSavaBDQ51yI+h48vWKwj1gKLOqKj6QdZ7vcp1TRPhKrYx8JIIXZ7gMzAJLNJCcLi0fziedWC5KwINCr3mK5ivlqLTaPpBvO9mbJOb6zXWu/3SjYCDRnBhx09G8bdNOWOf5mGr91g4V7VXSJbpi29AqnFdOW3qdU8Su4akHSySpzJOfgeFFObie7j6QZPNNWAx9IuPz8SN4GkbRTA+lMwI5FnrNdZ3nbXfKR+HXJFm7eUbga9KBi+lCXNFmhvFMG+4ilgO9s76zEBdCaaUt/n+4VbVb/7cR5Zo4hrmYT4xNXrFBPNseKMjE1bNrKOzaWjxXwm4NS++skIbFZHJV7BMAz13Ur/LeZCLdBp9nItKxjLjQXpxSZyT6SBuzcuAgv2bocpy5rv2/5hZsX46kja1oKw9MTgG6aJDUS+Vq7UVsAMKrKpAy5tlfkjonHsigyyU2bD7R2F5WEt3bREO58fBpASqYtYwLU2m+3w3/7mSPSaxaMacvQQpMaYHX1O1P5lgFm5cQQPnf1jo4+49z1i3Du+vhGNFHoSUFnKncjjwQAhpVGsnKy+VphJztDOTtCIwkKkqiQ17VTw7hjT3qCxJwAdYHQbvlImimRMujkF0geiWnNZB/JSY4uq6L7gdtditrSDn92tDfPkGvX+Qb0qk/3dRmO0DbN3uppTMBuhEbSrTwS2birtYCRQWPBJCQa5zwtQbJwr4oBR1/MJ0zTlhYknfhIVL2tFePsH2mWgmvXCQJ9fnQ5/rFCfQhxQJCkMDmZ/hDd26JbZpqxgosvvG0nzuqwV0aW8Z3tg62pm+bMtMJ/WZBklLCPpHvhv3LlvCqh1AYT5Ornr69rq6zPz+E5KUiiVuprp3xhnU7UVu98JABw0ealXfusLLJQNBJ9zm2LUqunx4Iko+S8qC1fI9ELpc4SEpVGwqatpnnrBRvrtumouiNzWiOJECSGRpJG2GzQtKUTaQd7dZ0mC02QLBrJdTRXtMJgH7EFjGfamvfDf7ti2lKChEN/O0NP0NOz0kcSpZEsHy+k6qQ2TTLd9pGcDPjO9sEWvvraTMs/ArAgySxhZ7tjGwmJHQiSzctGsXgkh9NXdtbO82RHC4ZpbdqK0Ehsi7B6UgrsNMJmozQSe8AnxTRZMAmJniBJr7p3T48YEe0iokeI6FEiui7i9YuJ6G4iqhDRa0OvXU1Eu9Xf1cb2/0xETxLRTC/H3m/qfSR+9d9Oona3rhzHXX/y0pO+zlan6FXf4dl5FFwrdvLR5q00nO1OpEbCgqRZFpppa+lC0EiIyAbwKQCXA9gG4I1EtC30ticAvBXAl0P7LgJwPYDzAewEcD0RTamXv622LWjCPhKzsVU3HahMe7iej6SM0Xx80cc1U8OBiLs0xgQYUVts2mqa3AIxbekFZ1rlUYDeOtt3AnhUCPEYABDRVwFcCeBX+g1CiD3qtXBTyJcBuE0IcVi9fhuAXQC+IoT4udrWw6H3H+3MPXhc1moaH3K9aK1OfCRMd9Cr//lqLbGG2pvPX9dRVYRWiPaR8LXSLDlbBkQMukZiWYQPXnF6YlvmbtNLQbIawJPG872QGka7+65u5cuJ6BoA1wDAunXrWtk1E+hJYe/0CQDA8vF8VxISme5gTjZJSXrbV09g++qUekIo7cMiYFiFebOPpHm2rx7H2Wsn+9Zzvptcc/EpqX5fLwVJ1BUsUthXvlmIGwHcCAA7duxoad8s4KpJYe/0HABg2XihK3kkTHdwI3I2+o1r2PhztgUi1kha4cVbl+PFW/vbT2VQ6aUOtxfAWuP5GgBPp7DvgsCySDYqmq9iyLUxlnf8RCM2bfUd07GdlbIhrro+pBAhDLn2wJtpmMGgl1fZHQA2E9FGIsoBuArALU3u+z0AlxHRlHKyX6a2nVToSWD5eB5ExD6SDBEwbWVFIwmVev/YldvxhvPWJu3CMF2hZ4JECFEBcC2kAHgIwNeFEA8S0Q1E9EoAIKLziGgvgNcB+CwRPaj2PQzgY5DC6A4ANxiO9z9X+wwT0V4i+kivfkO/0X6SZao8h5eQyIvMvuNGVNrtN1pL0gLld85dg9OWc74Q03t6egcIIW4FcGto24eNx3dAmq2i9r0JwE0R2/8QwB92d6TZRK8sdZ0n2/ORsEbSb4hkNeZqTWROI3Edvj6YdOG1bYbxTFsqHrwbrXaZ7qEd2VGVf/uBZ9pivwiTMnzFZRjfRxI0bS30HJpBQU/YWXG2h01bDJMWfMVlGN9HIjUS26u11bchMQZ64s5K+G8u5GxnmLTgKy7DhDUSvdBkH0k2cLKmkViskTD9ga+4DBN2tmuTFme2ZwOdt5EZQcI+EqZP8BWXYfQKc5lytnslUliOZAKdSZ4VZ7tXBp1NW0zK8BWXYVzbwlje8ZpR2Ry1lSn8qK2saCQ6s52vDyZdWJBkmJxjeY52wO9DwlFb2cDNmI8knNnOMGmRjTuAieTVz12NmVLFe861trKF1gBGMiNI2NnO9Ids3AFMJK85J5j0zz6SbOHaFvKOlRkNwMtsZ0HCpAxfcQOExVFbmcK1rMw42gHDR5IRwcacPPAVN0BYXGsrUzg2ZcbRDvg9Ujj8l0mb7NwFTEP0/MA+kmwwVnAwX8n1exge7gLpOc4MHixIBgjftNXngTAAgOtfcQYq1ew03+TMdqZfsCAZINi0lS1WTQ71ewgBcraFIdfG5HB2/DbMyQELkgHCj9piQcLUY1mEb117AVZnTMAxCx8WJAOEjtbizHYmDu6IyPQDNqYOENrJzgoJwzBZggXJAKEVETZtMQyTJViQDBBs2mIYJouwIBkg2LTFMEwWYUEyQFickMgwTAZhQTJAcB4JwzBZhAXJAOHlkbCPhGGYDNFTQUJEu4joESJ6lIiui3j9YiK6m4gqRPTa0GtXE9Fu9Xe1sf1cIrpffeYn6STq8uRrJH0eCMMwjEHPBAkR2QA+BeByANsAvJGItoXe9gSAtwL4cmjfRQCuB3A+gJ0ArieiKfXypwFcA2Cz+tvVo5+QObQgYR8JwzBZopcayU4AjwohHhNCzAP4KoArzTcIIfYIIe4DUAvt+zIAtwkhDgshpgHcBmAXEa0EMC6E+H9CCAHgCwBe1cPfkCnYtMUwTBbppSBZDeBJ4/leta2TfVerxw0/k4iuIaI7iejOgwcPNj3oLKOLurKznWGYLNFLQRI12zVbcztu36Y/UwhxoxBihxBix9KlS5v82mxD7CNhGCaD9FKQ7AWw1ni+BsDTHe67Vz1u5zMHHu0b4cx2hmGyRC8FyR0ANhPRRiLKAbgKwC1N7vs9AJcR0ZRysl8G4HtCiH0AjhPR81S01lsAfKsXg88iWoCcRIFqDMMMAD0TJEKICoBrIYXCQwC+LoR4kIhuIKJXAgARnUdEewG8DsBniehBte9hAB+DFEZ3ALhBbQOAdwH4HIBHAfwGwHd69RuyhpYf3EmVYZgs0dN+JEKIWwHcGtr2YePxHQiaqsz33QTgpojtdwLY3t2RDgYctcUwTBbhzPYBwuYSKQzDZBAWJAOExa12GYbJICxIBggvs53PGsMwGYKnpAHC4agthmEyCAuSAWL15BCuvfRUXLJlYSRYMgyzMOhp1BbTXSyL8P6Xben3MBiGYQKwRsIwDMN0BAsShmEYpiNYkDAMwzAdwYKEYRiG6QgWJAzDMExHsCBhGIZhOoIFCcMwDNMRLEgYhmGYjiAhmu1+O7gQ0UEAj7e5+xIAh7o4nG7B42qdrI6Nx9UaWR0XkN2xtTuu9UKIhqU0TgpB0glEdKcQYke/xxGGx9U6WR0bj6s1sjouILtj6/W42LTFMAzDdAQLEoZhGKYjWJA05sZ+DyAGHlfrZHVsPK7WyOq4gOyOrafjYh8JwzAM0xGskTAMwzAdwYKEYRiG6QgWJDEQ0S4ieoSIHiWi6/o8lrVE9CMieoiIHiSi31fbP0JETxHRPervij6MbQ8R3a++/061bRER3UZEu9X/qZTHtMU4JvcQ0TEiek+/jhcR3UREB4joAWNb5DEiySfVdXcfEZ2T8rj+GxE9rL77ZiKaVNs3ENEJ49h9JuVxxZ47IvojdbweIaKXpTyurxlj2kNE96jtaR6vuPkhvWtMCMF/oT8ANoDfANgEIAfgXgDb+jielQDOUY/HAPwawDYAHwHw/j4fqz0AloS2/TmA69Tj6wB8vM/ncj+A9f06XgAuBnAOgAcaHSMAVwD4DgAC8DwA/5ryuC4D4KjHHzfGtcF8Xx+OV+S5U/fBvQDyADaq+9ZOa1yh1/8CwIf7cLzi5ofUrjHWSKLZCeBRIcRjQoh5AF8FcGW/BiOE2CeEuFs9Pg7gIQCr+zWeJrgSwOfV488DeFUfx/JiAL8RQrRb2aBjhBD/F8Dh0Oa4Y3QlgC8Iyc8BTBLRyrTGJYT4vhCiop7+HMCaXnx3q+NK4EoAXxVClIQQvwXwKOT9m+q4iIgAvB7AV3rx3UkkzA+pXWMsSKJZDeBJ4/leZGTiJqINAJ4L4F/VpmuVenpT2iYkhQDwfSK6i4iuUduWCyH2AfIiB7CsD+PSXIXgzd3v46WJO0ZZuvbeBrly1Wwkol8S0e1EdFEfxhN17rJyvC4C8IwQYrexLfWmCr02AAAEK0lEQVTjFZofUrvGWJBEQxHb+h4nTUSjAL4J4D1CiGMAPg3gFABnA9gHqVqnzQVCiHMAXA7g3UR0cR/GEAkR5QC8EsA31KYsHK9GZOLaI6IPAagA+JLatA/AOiHEcwG8D8CXiWg8xSHFnbtMHC8Ab0RwwZL68YqYH2LfGrGto2PGgiSavQDWGs/XAHi6T2MBABCRC3mRfEkI8Q8AIIR4RghRFULUAPwNeqTSJyGEeFr9PwDgZjWGZ7SqrP4fSHtcissB3C2EeEaNse/HyyDuGPX92iOiqwG8HMCbhTKqK9PRs+rxXZC+iNPSGlPCucvC8XIAvAbA1/S2tI9X1PyAFK8xFiTR3AFgMxFtVKvaqwDc0q/BKPvr3wJ4SAjxCWO7add8NYAHwvv2eFwjRDSmH0M6ah+APFZXq7ddDeBbaY7LILBK7PfxChF3jG4B8BYVWfM8AEe1eSINiGgXgA8AeKUQYs7YvpSIbPV4E4DNAB5LcVxx5+4WAFcRUZ6INqpx/SKtcSleAuBhIcRevSHN4xU3PyDNayyNqIJB/IOMbPg15EriQ30ey4WQqud9AO5Rf1cA+DsA96vttwBYmfK4NkFGzNwL4EF9nAAsBvBDALvV/0V9OGbDAJ4FMGFs68vxghRm+wCUIVeDb487RpBmh0+p6+5+ADtSHtejkPZzfZ19Rr33d9Q5vhfA3QBekfK4Ys8dgA+p4/UIgMvTHJfa/r8BvDP03jSPV9z8kNo1xiVSGIZhmI5g0xbDMAzTESxIGIZhmI5gQcIwDMN0BAsShmEYpiNYkDAMwzAdwYKEYTIMEV1CRP+n3+NgmCRYkDAMwzAdwYKEYboAEf1bIvqF6j3xWSKyiWiGiP6CiO4moh8S0VL13rOJ6Ofk9/zQfSJOJaIfENG9ap9T1MePEtHfk+wT8iWVycwwmYEFCcN0CBFtBfAGyAKWZwOoAngzgBHIWl/nALgdwPVqly8A+IAQ4jmQmcV6+5cAfEoIcRaAF0BmUQOymut7IHtMbAJwQc9/FMO0gNPvATDMAuDFAM4FcIdSFoYgC+TV4Bfy+yKAfyCiCQCTQojb1fbPA/iGqlm2WghxMwAIIYoAoD7vF0LVcSLZgW8DgJ/0/mcxTHOwIGGYziEAnxdC/FFgI9GfhN6XVI8oyVxVMh5XwfctkzHYtMUwnfNDAK8lomWA1yt7PeT99Vr1njcB+IkQ4iiAaaPR0e8CuF3I/hF7iehV6jPyRDSc6q9gmDbhlQ3DdIgQ4ldE9MeQnSItyOqw7wYwC+AMIroLwFFIPwogS3p/RgmKxwD8ntr+uwA+S0Q3qM94XYo/g2Hahqv/MkyPIKIZIcRov8fBML2GTVsMwzBMR7BGwjAMw3QEayQMwzBMR7AgYRiGYTqCBQnDMAzTESxIGIZhmI5gQcIwDMN0xP8HaDiC3iZHAGwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist3_1.history['acc'])\n",
    "plt.plot(hist3_1.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## summarize history for loss\n",
    "plt.plot(hist3_1.history['loss'])\n",
    "plt.plot(hist3_1.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 31, 31, 32)        1056      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 31, 31, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 31, 31, 64)        2112      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 30, 30, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 128)       8320      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 29, 29, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 107648)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               53824500  \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 53,893,766\n",
      "Trainable params: 53,893,766\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3_2 = Sequential()\n",
    "model3_2.add(Conv2D(filters = 32, kernel_size = (5, 5), strides = (1, 1), padding = 'same', input_shape = x_train.shape[1:]))\n",
    "model3_2.add(Activation('relu'))\n",
    "model3_2.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1), padding = \"valid\"))\n",
    "\n",
    "model3_2.add(Conv2D(filters = 32, kernel_size = (1, 1), strides = (1, 1), padding = 'same'))\n",
    "model3_2.add(Conv2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "model3_2.add(Conv2D(filters = 64, kernel_size = (1, 1), strides = (1, 1), padding = 'same'))\n",
    "model3_2.add(Activation('relu'))\n",
    "model3_2.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1), padding = \"valid\"))\n",
    "\n",
    "model3_2.add(Conv2D(filters = 64, kernel_size = (1, 1), strides = (1, 1), padding = 'same'))\n",
    "model3_2.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same'))\n",
    "model3_2.add(Conv2D(filters = 128, kernel_size = (1, 1), strides = (1, 1), padding = 'same'))\n",
    "model3_2.add(Activation('relu'))\n",
    "model3_2.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1), padding = \"valid\"))\n",
    "\n",
    "model3_2.add(Flatten())\n",
    "model3_2.add(Dense(500))\n",
    "model3_2.add(Activation('relu'))\n",
    "model3_2.add(Dense(num_classes))\n",
    "model3_2.add(Activation('softmax'))\n",
    "\n",
    "model3_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.0978 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 2/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.0966 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 3/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.1001 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 4/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0987 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 5/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0988 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 6/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0979 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 7/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0992 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 8/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0973 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 9/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0952 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 10/200\n",
      "10000/10000 [==============================] - 1s 101us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.0991 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 11/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 148ms/step - loss: 0.0000e+00 - acc: 0.0997 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 12/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0977 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 13/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0964 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 14/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0988 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 15/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 16/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0969 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 17/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0978 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 18/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0987 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 19/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 149ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 20/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0985 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 21/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0970 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 22/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0998 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 23/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 24/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.1003 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 25/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0982 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 26/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0977 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 27/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0975 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 28/200\n",
      "10000/10000 [==============================] - 1s 102us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0997 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 29/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 29s 150ms/step - loss: 0.0000e+00 - acc: 0.0982 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 30/200\n",
      "10000/10000 [==============================] - 1s 103us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 31/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0971 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 32/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0983 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 33/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 34/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0983 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 35/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0994 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 36/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0991 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 37/200\n",
      "10000/10000 [==============================] - 1s 104us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0982 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 38/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 39/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0960 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 40/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 151ms/step - loss: 0.0000e+00 - acc: 0.0957 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 41/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0981 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 42/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0973 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 43/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0976 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 44/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0962 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 45/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 0.0000e+00 - acc: 0.0989 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 46/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0979 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 47/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.0968 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 48/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 161ms/step - loss: 0.0000e+00 - acc: 0.0986 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 49/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 0.0000e+00 - acc: 0.0981 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 50/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 51/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0996 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 52/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 0.0000e+00 - acc: 0.0978 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 53/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 152ms/step - loss: 0.0000e+00 - acc: 0.0995 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 54/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 0.0000e+00 - acc: 0.0978 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 55/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 0.0000e+00 - acc: 0.0956 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 56/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0974 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 57/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 153ms/step - loss: 0.0000e+00 - acc: 0.0981 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 58/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0976 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 59/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 60/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.0989 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 61/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0979 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 62/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 63/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 64/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0975 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 65/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.0965 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 66/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0976 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 67/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0977 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 68/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0973 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 69/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 70/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 71/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0995 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 72/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0977 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 73/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 154ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 74/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 75/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0981 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 76/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.0967 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 77/200\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 161ms/step - loss: 0.0000e+00 - acc: 0.0982 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 78/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 161ms/step - loss: 0.0000e+00 - acc: 0.0973 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 79/200\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 161ms/step - loss: 0.0000e+00 - acc: 0.0974 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 80/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0985 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 81/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 0.0000e+00 - acc: 0.0947 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 82/200\n",
      "10000/10000 [==============================] - 1s 119us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.0978 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 83/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 156ms/step - loss: 0.0000e+00 - acc: 0.0981 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 84/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 30s 155ms/step - loss: 0.0000e+00 - acc: 0.0976 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 85/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 86/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0972 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 87/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0964 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 88/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 89/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0991 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 90/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0998 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 91/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0976 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 92/200\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0958 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 93/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 164ms/step - loss: 0.0000e+00 - acc: 0.0972 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 94/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0994 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 95/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0992 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 96/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.0968 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 97/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0949 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 98/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.0961 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 99/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 166ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 100/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0999 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 101/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 161ms/step - loss: 0.0000e+00 - acc: 0.0993 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 102/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0987 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 103/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0979 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 104/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 168ms/step - loss: 0.0000e+00 - acc: 0.1010 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 105/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 106/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0981 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 107/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.1002 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 108/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.0969 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 109/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 161ms/step - loss: 0.0000e+00 - acc: 0.0989 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 110/200\n",
      "10000/10000 [==============================] - 1s 118us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0988 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 111/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 167ms/step - loss: 0.0000e+00 - acc: 0.0987 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 112/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 166ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 113/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0993 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 114/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 164ms/step - loss: 0.0000e+00 - acc: 0.1009 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 115/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 167ms/step - loss: 0.0000e+00 - acc: 0.0977 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 116/200\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.0979 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 117/200\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 168ms/step - loss: 0.0000e+00 - acc: 0.1009 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 118/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 164ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 119/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 34s 172ms/step - loss: 0.0000e+00 - acc: 0.0987 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 120/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 34s 171ms/step - loss: 0.0000e+00 - acc: 0.0964 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 121/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 167ms/step - loss: 0.0000e+00 - acc: 0.0974 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 122/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0974 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 123/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0982 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 124/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 125/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 161ms/step - loss: 0.0000e+00 - acc: 0.0992 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 126/200\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 166ms/step - loss: 0.0000e+00 - acc: 0.0988 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 127/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 168ms/step - loss: 0.0000e+00 - acc: 0.1005 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 128/200\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 166ms/step - loss: 0.0000e+00 - acc: 0.0986 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 129/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 169ms/step - loss: 0.0000e+00 - acc: 0.0966 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 130/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 170ms/step - loss: 0.0000e+00 - acc: 0.0990 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 131/200\n",
      "10000/10000 [==============================] - 1s 116us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 168ms/step - loss: 0.0000e+00 - acc: 0.0966 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 132/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.0982 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 133/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 167ms/step - loss: 0.0000e+00 - acc: 0.0975 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 134/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0999 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 135/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 136/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0991 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 137/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 138/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0974 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 139/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0968 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 140/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.0963 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 141/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 161ms/step - loss: 0.0000e+00 - acc: 0.0977 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 142/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.0998 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 143/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.0992 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 144/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 169ms/step - loss: 0.0000e+00 - acc: 0.0986 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 145/200\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 167ms/step - loss: 0.0000e+00 - acc: 0.1003 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 146/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 166ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 147/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0979 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 148/200\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 34s 174ms/step - loss: 0.0000e+00 - acc: 0.0996 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 149/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 167ms/step - loss: 0.0000e+00 - acc: 0.0972 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 150/200\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 166ms/step - loss: 0.0000e+00 - acc: 0.0998 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 151/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0959 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 152/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 164ms/step - loss: 0.0000e+00 - acc: 0.0983 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 153/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.0973 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 154/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.0994 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 155/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0988 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 156/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 157ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 157/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.1004 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 158/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0985 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 159/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 169ms/step - loss: 0.0000e+00 - acc: 0.1005 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 160/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0975 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 161/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 169ms/step - loss: 0.0000e+00 - acc: 0.0997 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 162/200\n",
      "10000/10000 [==============================] - 1s 115us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 163/200\n",
      "10000/10000 [==============================] - 1s 118us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 34s 174ms/step - loss: 0.0000e+00 - acc: 0.0969 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 164/200\n",
      "10000/10000 [==============================] - 1s 111us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 33s 168ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 165/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.0993 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 166/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.0973 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 167/200\n",
      "10000/10000 [==============================] - 1s 114us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 37s 189ms/step - loss: 0.0000e+00 - acc: 0.0979 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 168/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 161ms/step - loss: 0.0000e+00 - acc: 0.0969 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 169/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0992 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 170/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.0992 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 171/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 161ms/step - loss: 0.0000e+00 - acc: 0.0976 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 172/200\n",
      "10000/10000 [==============================] - 1s 109us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0980 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 173/200\n",
      "10000/10000 [==============================] - 1s 113us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0972 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 174/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 162ms/step - loss: 0.0000e+00 - acc: 0.1000 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 175/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.1008 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 176/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.1004 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 177/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0991 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 178/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.0967 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 179/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.1008 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 180/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0998 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 181/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0979 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 182/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.0969 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 183/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.0984 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 184/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0988 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 185/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 160ms/step - loss: 0.0000e+00 - acc: 0.0982 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 186/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 163ms/step - loss: 0.0000e+00 - acc: 0.0978 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 187/200\n",
      "10000/10000 [==============================] - 1s 112us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 161ms/step - loss: 0.0000e+00 - acc: 0.0993 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 188/200\n",
      "10000/10000 [==============================] - 1s 108us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 165ms/step - loss: 0.0000e+00 - acc: 0.0973 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 189/200\n",
      "10000/10000 [==============================] - 1s 110us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 32s 164ms/step - loss: 0.0000e+00 - acc: 0.0962 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 190/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0963 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 191/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0995 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 192/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0982 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 193/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0976 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 194/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.1002 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 195/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0967 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 196/200\n",
      "10000/10000 [==============================] - 1s 105us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0999 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 197/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0969 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 198/200\n",
      "10000/10000 [==============================] - 1s 107us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0977 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 199/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 158ms/step - loss: 0.0000e+00 - acc: 0.0970 - val_loss: 0.0000e+00 - val_acc: 0.0746\n",
      "Epoch 200/200\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "196/196 [==============================] - 31s 159ms/step - loss: 0.0000e+00 - acc: 0.0986 - val_loss: 0.0000e+00 - val_acc: 0.0746\n"
     ]
    }
   ],
   "source": [
    "temperature = 1\n",
    "logits_T2 = logits / temperature\n",
    "y_train_soft2 = np.array([softmax(logit) for logit in logits_T2])\n",
    "\n",
    "model3_2.compile(loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, lambda_const = 0),\n",
    "               optimizer=tf.keras.optimizers.Adam(lr=0.0001, decay=1e-8), \n",
    "               metrics=['accuracy'])\n",
    "\n",
    "# Fit\n",
    "hist3_2 = model3_2.fit_generator(datagen.flow(x_train, y_train,\n",
    "\tbatch_size=batch_size),\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=(x_test, y_test),\n",
    "\tworkers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\Justin\\Desktop\\Assignment1\\saved_models\\C_Model2_Weights.h5 \n"
     ]
    }
   ],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, 'C_Model2_Weights.h5')\n",
    "model3_2.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 163us/sample - loss: 0.0000e+00 - acc: 0.0730\n",
      "Train loss: 0.0\n",
      "Train accuracy: 0.07296\n",
      "10000/10000 [==============================] - 2s 165us/sample - loss: 0.0000e+00 - acc: 0.0746\n",
      "Test loss: 0.0\n",
      "Test accuracy: 0.0746\n"
     ]
    }
   ],
   "source": [
    "# Score trained model.\n",
    "train_scores2 = model3_2.evaluate(x_train, y_train, verbose=1)\n",
    "print('Train loss:', train_scores2[0])\n",
    "print('Train accuracy:', train_scores2[1])\n",
    "test_scores2 = model3_2.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', test_scores2[0])\n",
    "print('Test accuracy:', test_scores2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXl8nFW9/9/f2SeZ7EmTpum+QVva0pZC2ZeCKDsii+ACyqZcFf3pxYtekOvG9aqgXHEF0SsFFJCCQG1ZRGyB7i3d6ELbpNn3ZTL7+f3xLJlJJsk0aWhLz/v1yisz82zneWae8znf7TyilEKj0Wg0mqHiONwN0Gg0Gs3RjRYSjUaj0QwLLSQajUajGRZaSDQajUYzLLSQaDQajWZYaCHRaDQazbDQQqLRDICI/F5EvpvhuntFZPFIt0mjOdLQQqLRaDSaYaGFRKM5BhAR1+Fug+bDixYSzVGP6VL6uohsEpEuEfmdiJSKyEsi0iEiK0SkIGn9S0Vki4i0isjrInJ80rITRWSdud2TgK/XsS4WkQ3mtitFZHaGbbxIRNaLSLuIVIrIvb2Wn27ur9Vc/lnzc7+I/FhE9olIm4i8aX52tohUpbkOi83X94rIX0Tk/0SkHfisiCwUkVXmMWpE5CER8SRtP1NElotIs4jUich/iEiZiARFpChpvfki0iAi7kzOXfPhRwuJ5sPCx4HzgWnAJcBLwH8AxRi/8y8BiMg0YAnwFaAEeBF4XkQ8Zqf6V+CPQCHwZ3O/mNvOAx4BbgWKgF8BS0XEm0H7uoBPA/nARcDtInK5ud9xZnt/brZpLrDB3O5/gPnAqWabvgEkMrwmlwF/MY/5JyAO3Glek0XAecAXzDbkACuAl4FyYArwilKqFngduDppvzcATyilohm2Q/MhRwuJ5sPCz5VSdUqpA8A/gbeVUuuVUmHgWeBEc71rgL8ppZabHeH/AH6MjvoUwA08oJSKKqX+AqxOOsbNwK+UUm8rpeJKqceAsLndgCilXldKbVZKJZRSmzDE7Cxz8fXACqXUEvO4TUqpDSLiAG4CvqyUOmAec6V5TpmwSin1V/OY3UqptUqpt5RSMaXUXgwhtNpwMVCrlPqxUiqklOpQSr1tLnsMQzwQESdwHYbYajSAFhLNh4e6pNfdad4HzNflwD5rgVIqAVQCY8xlB1TqTKb7kl6PB75muoZaRaQVGGtuNyAicrKIvGa6hNqA2zAsA8x97E6zWTGGay3dskyo7NWGaSLygojUmu6u72fQBoDngBkiMgnD6mtTSr0zxDZpPoRoIdEca1RjCAIAIiIYnegBoAYYY35mMS7pdSXwPaVUftJfllJqSQbHfRxYCoxVSuUBvwSs41QCk9Ns0wiE+lnWBWQlnYcTwy2WTO+pvR8GtgNTlVK5GK6/wdqAUioEPIVhOX0KbY1oeqGFRHOs8RRwkYicZwaLv4bhnloJrAJiwJdExCUiVwILk7b9DXCbaV2IiGSbQfScDI6bAzQrpUIishD4ZNKyPwGLReRq87hFIjLXtJYeAX4iIuUi4hSRRWZM5j3AZx7fDXwLGCxWkwO0A50ichxwe9KyF4AyEfmKiHhFJEdETk5a/gfgs8ClwP9lcL6aYwgtJJpjCqXUDgx//88xRvyXAJcopSJKqQhwJUaH2YIRT3kmads1GHGSh8zlu8x1M+ELwH0i0gH8J4agWfvdD3wMQ9SaMQLtc8zF/w/YjBGraQbuBxxKqTZzn7/FsKa6gJQsrjT8PwwB68AQxSeT2tCB4ba6BKgFdgLnJC3/F0aQf50ZX9FobEQ/2Eqj0WSCiLwKPK6U+u3hbovmyEILiUajGRQROQlYjhHj6Tjc7dEcWWjXlkajGRAReQyjxuQrWkQ06dAWiUaj0WiGhbZINBqNRjMsjomJ3IqLi9WECRMOdzM0Go3mqGLt2rWNSqne9Ul9OCaEZMKECaxZs+ZwN0Oj0WiOKkRk3+BradeWRqPRaIaJFhKNRqPRDAstJBqNRqMZFsdEjCQd0WiUqqoqQqHQ4W6KJkN8Ph8VFRW43fp5ShrNkcQxKyRVVVXk5OQwYcIEUid71RyJKKVoamqiqqqKiRMnHu7maDSaJI5Z11YoFKKoqEiLyFGCiFBUVKQtSI3mCOSYFRJAi8hRhv6+NJojk2NaSDSaI41ILMFTqytJJPTURZqjBy0kh4mmpibmzp3L3LlzKSsrY8yYMfb7SCSS0T5uvPFGduzYcdDHvuiiizjjjDMOejvNyPP6jnq+8fQmNla1Dmn73Q2ddEfi9vu69hC/eWMPek49zUiiheQwUVRUxIYNG9iwYQO33XYbd955p/3e4/EARoA5kUj0u49HH32U6dOnH9Rxm5qa2Lx5M3V1dezfv39Y5zAQsVhsxPb9YaYlaAwiWoPRg942HItz8c/e5LFVe+3PXthUw/de3EZVS/chaqGmN7/6x27uXbqlz+erdjfx8Ou7D0OLPni0kBxh7Nq1i1mzZnHbbbcxb948ampquOWWW1iwYAEzZ87kvvvus9c9/fTT2bBhA7FYjPz8fO666y7mzJnDokWLqK+vT7v/v/zlL1x++eVcc801PPmk/YA8amtrueyyy5g9ezZz5szh7bffBgyxsj678cYbAbjhhhv461//am8bCAQAWLFiBYsXL+baa6/lxBNPBOCSSy5h/vz5zJw5k9/+tud5SH/729+YN28ec+bM4YILLiAejzNlyhSam5sBiMfjTJo0yX5/rNDebQhwa3dmVmkyVS3ddEfj1Lb1JCS0mcJU266TFEYCpRS/X7mX36/cy8pdjSnLnl1fxY+WbScY+fAPqo7Z9N9kvvP8FrZWtx/Sfc4oz+WeS2YOadutW7fy6KOP8stf/hKAH/7whxQWFhKLxTjnnHO46qqrmDFjRso2bW1tnHXWWfzwhz/kq1/9Ko888gh33XVXn30vWbKEH/zgB+Tl5XHDDTfw9a9/HYAvfvGLnH/++dxxxx3EYjGCwSAbN27k/vvvZ+XKlRQWFmbUqb/11lts3bqVcePGAfDYY49RWFhIMBhkwYIFfPzjHyccDnP77bfzz3/+k/Hjx9Pc3IzT6eS6667j8ccf54477mDZsmWcdNJJFBYWDukaHq20dRuWSNsQLJL9zUEA2rt7tm01XyeLS6YEIzFu+O3bfOfSWZxQkXfQ2x8JxOIJfvH6bj572gRyfYe+/mhfU5Aa89re98JW/valM3A6jKSQrnCchILNVW2cPKnokB/7SEJbJEcgkydP5qSTTrLfL1myhHnz5nHivHls27aNrVu39tnG7/fz0Y9+FID58+ezd+/ePuscOHCA/fv3c8oppzBjxgzi8Tjbt28H4PXXX+fWW28FwOVykZuby6uvvso111xjd+aZdOqLFi2yRQTgpz/9qW0lVVVVsXv3blatWsU555zD+PHjU/b7uc99jsceewyARx55xLaAjiXaQ6aQdB/8KLbSFJK2JCFpG4aQ7KrvZN3+VlbtaRx85UNAXXuIjZVDiw0lE40n+M0bewjH4mw60MZPlr/Ha9vTW+jDZeXuJgC+sngq22s7eH1Hz3E6w8Z3ONR419HEiFokInIh8CDgBH6rlPphr+VnAg8As4FrlVJ/SVr2GeBb5tvvKqUeMz+fD/we8AMvAl9Ww4wkDtVyGCmys7Pt1zt37uTBBx/kmWWv483K4Ttfuz1tLYUVVwFwOp1pYxRPPvkkTU1NdkFfW1sbTzzxBPfeey/QN71WKZU25dblctmxm3g8nnKs5LavWLGCN954g7feegu/38/pp59OKBTqd78TJkygoKCA1157jfXr13PBBRekvT4fZmyLJEkMXtlWRzAS55I55QNuu7+pr5BYsZahuLaqW424Sl17+KC3HQoPrNjJ37fUsvbb5w9rP2/taeJ7L25jQnE2cfN3mnxNDiWr9jRRmuvl82dM4oEVO9le28F5x5cC0GUKyYZDII692VHbQWNnmNOmFB/yfQ+FEbNIRMQJ/C/wUWAGcJ2IzOi12n7gs8DjvbYtBO4BTgYWAveISIG5+GHgFmCq+XfhCJ1CCsFILCUb5oOivb2dnJwcPP4AVQeqWbZs2ZD3tWTJElasWMHevXvZu3cv77zzDkuWLAHgnHPOsV1p8Xic9vZ2Fi9ezBNPPGG7tKz/EyZMYO3atQA8++yzxOPpr0tbWxuFhYX4/X62bNnC6tWrATjttNN49dVX2bdvX8p+wbBKrr/+eq699locjmPPYE4nJL96Yw//+9quQbfdP5BFMgQhsQL0H1R8pbI5SFNXhFB0ePeZZX3VtnXbr4fiKhwMpRSrdjexaFIRAa+L0Xk+dtd32stti6Sy7ZAf+2ev7OSuZzYd8v0OlZG8UxcCu5RSe5RSEeAJ4LLkFZRSe5VSm4DeqUkfAZYrpZqVUi3AcuBCERkN5CqlVplWyB+Ay0fwHGyqW0P2CO2DZN68ecyYMYOPnbmQe77xJU499bR+120NRnivtiMl1fNAS5CWrgi7d++mtraWBQsW2MumTp2K1+tl7dq1PPTQQyxbtowTTjiBBQsWsH37dmbPns03vvENzjzzTObOnWvHU2699VaWL1/OwoUL2bBhA16vN217LrroIoLBIHPmzOG+++7j5JNPBqC0tJSHH36Yyy67jDlz5nD99dfb21xxxRW0tbXx2c9+djiX7YgnGk+wu6Gzz+fttpD0BNsbO8J0hAZ3ddkxklBfIakbgmurujU05G2HQnWbZQEN73j1HYYFVdMWos583ToCFsnuhk4aO8MsmmzEP6aMCrAr6TvtMoPsB1q7qe84tNewsTNsi2NnOEZN2+HNyhtJ19YYoDLpfRWGhTHUbceYf1VpPu+DiNyCYbmk+OyHSjyhbDP5UGO5lgCmTJnChg0bAKNTSSjFH/7wB96tbkcpxfTSHLxuJwBvvvmmvV1raysHWrsJxeJ84upruO6661BK0RyMEo0rJk+eTGVlJb3ZtKlnVPP888/3WX7TTTdx0003pXw2evRo3nnnHfv9d7/7XQAWL17M4sWL7c99Pl+/FtRFF13ERRdd1OfzdevWsXDhQqZOnZp2uyOJ9ftbCMcSnDKEQOqSd/bznee38spXz2JCcY87MJ1F0tARhkGK+pVSA8dIhuHaymTbdw+08YvXd/HgtSfidmY2Pk0kFA4zMK2U6jleW4jxRdl91l++tY5ppYG0y5KxhKi2LWRft6GkUw9GpWmxTS3NAWBySYA/r6m0Xbdd4TjHleWwvbaDjZVtnD/Dd8iO3RKM0BmOoZTiZ6/s5MXNNbz57+cesv0fLCNpkaT76Wcay+hv24z3qZT6tVJqgVJqQUnJoE+KHJR4QhFLKGLxzMQknkgM20Rv6AxT1x4illC2lRHtVfHcGoywt7HLWBZL2G0F7O2iGbb5cPO9732Pa665hu9///uHuykZ8e9Pb0pbP5AJb+9pJp5QPL+xOuVzK8huCUB3JE5HOEZnODZgtXtLMEpXJE5RtodQNEE4Fkcp1WORtIcOulreshDq28ODFjS+sbOBFzfX2lbRYNS2hZh17zI7ZbY1GCUUNX6nlhWRjFKKLy1Zz6P/2pvRvsGwSOrN+E5bd5RILMGdT25IawkOhVYztTrfb2SDTS7JpisSt2NKneEYJ00wEkneq+s4JMe0aO6KklAQjMSpbu2mpi10WItOR1JIqoCxSe8rgOp+1s102yrz9VD2OSzi5pcUjmXWKde0hdhd3zmsLzeeUERiqULQW8g6wzHaQ1FiiYS9XszsMCJmWyMfkJBEYgmqWoIkhnjOd999N/v27WPRokWHuGWHnsrmIO/VdRrWwhBYt78FgOc3pf58e7K2jP+Nncb+lYLOAeoRrA581pg8e/vOcIx4QlFR4CcaVzQHD642pbq1G4cYv5+WQUb0TZ3GvjN1g+2q7yQYifPkGsNKPpDkNrb2kUgozv/JP3h2fRXd0Tjd0XhGLj5LiGrbQ7Y11dYd4f3GLp5df4BXtx2aDC7LyinIMhJdJpcY9VS7GzqJxhNEYglKcrzk+d1DyppLJnlQmkgou3C1IxSjrTtKPKHsmMzhYCSFZDUwVUQmiogHuBZYmuG2y4ALRKTADLJfACxTStUAHSJyihhpP58GnhuJxieTSLIIMhGSRELRFowSV8q2DoZCPKFQKLrCPT+iaDx1fzHzfTSWsJdZx7SExXDLGecwkqOW9lCUZjNYGokleL+xK2MLbrh85Yn1/NcLfdOiR4oV2+oAaA5G+pxjfXuI9aZQpKOmzRhBTisN8F5dJ9trjRom67qJ9HRS9UlCNVAnagnJCaaQtHdHbTGabrpeDqYzC0XjNHZGmF6Wm9G2TZ09cYlMsGIGK7bW0R2Jp2xnuaYaOsPsrO9kY2UbzV1Gx9kZ7itoT62uZPnWup59t1sWSbe9r9Zg1Bb9A4co1tkSjCICuaZFMmVUj5AEzXs22+uiLNc3rISF3Q2dzLpnGe8eMIL2HaGYfY93hKK0m7+LkXDfZcqICYlSKgbcgSEK24CnlFJbROQ+EbkUQEROEpEq4BPAr0Rki7ltM/BfGGK0GrjP/AzgduC3wC5gN/DSSJ2DRTyp8w3HUt1ViURfsegIR+1teruiDuq45rZdSSONWK84jWV9hGMJe5l17GRLJBpPsKexi31NwRETE8sCisaN0VFHKEr3MN17mfDugTb+uqGaf+36YOodAF4xR7VKYXdyFg+8spOrfrmKf7zXkHbbdfuMdNBvfvR4nA5h6QbDKrE6/tG5PsIxwzWabPG0DxAwrrQtklxzXzG7Y5leZgjJwQSxrY593rj8jLZt6jq4CnrL/dMVifPajno7PpLjddkWhdXhN3dFaOkyziV5UGXxs1d38oMXtwHG/VjfESbb4yQUTdji29YdpaHTaFvvpJlEQvHJ37zFsi21GbXdojUYIc/vtgsQS3K85Hhd7KrvtK3HgNdJaZ4vIxHf3xTkjsfX9XGJ72vqIpZQrDfTiJMty/ZQjI40cbUPmhHNr1RKvaiUmqaUmqyU+p752X8qpZaar1crpSqUUtlKqSKl1MykbR9RSk0x/x5N+nyNUmqWuc87hltDkgnJvuVwNLUjr27r5n0zRmGRPDIY6og8kVC2i6grEkMQ3E6HbYH03n+yWWtbJEnWUziWIBiO0x6K2u6SQ40tJLGELWKRDF2Bw+GX/zDmM/qgsuo6QlHefr+JiWaQvL6Xe6u2LUQ8ofjin9axJ40/ft3+FrwuB6dNKebUyUU8v6kapZQtFGMLswBDOBo6M7NI3m/sYlSOl9Jcn72ttT9LSDKxFjrDMb765Abe2mMU2s0bZ2TdDyYkluBlavXUd4TI9jgpDnh5YVM11W3deJwOjh+da7u2rO+zqStsd5693TdKKRo6wuxp7GJXfSdNXRHiCZVSiV+S46W1O2rHS6p7ZThVt3WzcncTq8ziwmSeXlvF3c9u5n+W7egzYGwJRm23Fhh1WJNGBdjd0GkP/rK9LkZnaJGs2FbHC5tq+sRTrGlzrNTi5IFLRyiaNkHjg+bYS9QfAtYI3yHSx7XVHYn38V+2h2L2dAy9XVGZEkv60cYTCpfTEJLkeIlSyrZ4kkdq1g8+Ele4zFqMjlAUhcLtdFDbFiYSi5NQisbO8JBjGr2xxSOesEVssEB/ZyjaR2yVUtS2h+geZI6iYCTGk6v38+LmGvL8btpDsZSOZqTcamv2tRCNKz4+z0gYbOglzA0dYY4ry6EzHOPlNKPc9ftbOGFMHh6Xg0vnlFPZ3M2Gyla7IxhnCklbdzRji2RPQyeTSrJtN0tbd9ROeZ1cEsAhmVkkr++o55n1B/iu6SacM9awSKyOcFNVa9qJCC2LpKYtxNp9LZzx368OmPJa3x6mNM/Hx04o49Xt9eyq62R0vo+yPB91Hb2EpDNCi7n/rl5C0hGO2ffk8q119jla7QbDtReJJahsCZr7TW3X7gZjIJiuvd97cRtPrK7kodd29ZlGybJIkplYlMW+pqD9O8z2uCjN89HYGR70XtjXZLSjdwGoFTezkgRaUoQk1ieudjjQQpIBVsfsdzuJxBO2a0gpRTiWIKF6UoOtTKmAz8is7h0otzrtwaaR7z36cTsduJ2SIkwJpXhmyR9prK9LcbnZQhJL4CLOGbMm8r377gVgTL4fheF6au+OUt3a3efmTEdskCw0pVSSayvJIhlASMPROHsau9hR12FnwBjXSVHfHho0wHv7/63j35/ezNRROfzbuVMAqDE7n8rmIDPvWcbbe/qOMofL9hpjxHj29FGAUeeRTGNnmFlj8sjyOO0gdMr2tR12UPwjs8rwOB0s3Vhtdwj9CUlHOMqq3U38z7Id7KpPHbW+39jFpJKA3bG1JcVIigIeKgqyWL61btDv+l+7jOvVFYkjAmML/RQHPHYH/fTaKu5/eXuKSCcSyh4l17WH+Md7DVQ2d9vuv3TUd4QYlePl4tnlhKIJXttRz+g8H6W5XmrNDCSrw2/qitjB5d4WSfL1+fvWWrudJyYJyTQzRrQraUSfXFxsjfTre3Xg0XiC5q4Ii483vmdLiCxaghEKslKFpDjgpbkrkmKRlOX6UIpBEzP2me7J3oJvDSD2mIKX7Nqq7wjbfcKHMkbyYcJybfk9TpRS7GsKmiOMHveT9WVa710OweWQlBtuZ32nbfoPNo28JUwu0//qdgoupyMlRhKNK/761P/R1NBzw7ocjpS035Wvr2DKtON48blncIiQ43PhcjjoCsftH3smCQGNHRF21Xf2a72EItGUaxFNcnP1hzWSdIhQ1dJtC7QVVxnILaaUYt2+Fq5eUMHLXznDHoFWm9f37febCccSvLrj0M+xtL22nTH5fiaVGK6tZItEmVZeccBLccDbx40YisYJRuKU5BhFnLk+N2dPL+Fvm2rsOIDl2rICxKPMddu7Y/zuzT089NouFv/kDe54fB3Vrd20dEVoCUaZVJxtC0l7d9TuWPL9Hu69dAbv1XXwlSc3DBgjW7m7kdOmFFGS46Uk4MXrclKa2+PjtyyPZJG3soZEDItkW40xcn91gPmt6trDjMrxsWB8AWW5PhIKyvP8lJrxofbumB0jaemK2ILcn5CcPLGQDZWtbKoyAtIzy/Mwbx2mlxlB8J11PW7GZPeWVURY18siscTxRNO9t68pVUhae7m2AIoCXoKRuP29Z3udjM4z3I3JrsVILMG5P36dX7zeM2OBNcVNb1epFUw/0NpNdySeYpEcSHo8gLZIjnAs11aOz4WI0BmOUd9uuIcsLMvDEh2HGB2/LTAJZY9wertcWoOG6W7d4I899hhnnX4qV3/kDL7/rf9HIpFAVIKv3PY5Lj93EbNmzeJnP/sZTz75JDu2vMu/f/Emrv7IGSRiUdwusbO0Ekqx9Nk/87nb76CouIT33t2AiJDlcbLqrbe46Pyz+cQFp3PeWacTDAaJxWLceeedzJo1i9mzZ/OLX/wCgIqKChqbm0koxRtv/ssuOvzmf9zNLbfcwvnnn89NN95I5d73ufHjH+OSc0/lyo+cyab1a2zL5Pvf/z4nnHACc+bM4e6772bHjh2cffqpgDGK2/Xedk5auBDoEZKBMuTau2N0hGNMK81BRCjP9wM97pDN5kR5a/f2nz01VLbXdHBcWQ5ZHhcBrytlpNnWbRSAluR4KQp4+lgk1ugy2SVy0ezR1HeEedNMFhibbJF0hm3B6ghFqe8IM398AV86dwrLt9Zxza9X2S6PSSXZuJ0OsjxO2yLxOB343A7OPa6UOxdPY/nWOtuV05uqliD7moIsPr6Un193It+62JjRqDTXZ7tbrPNp6uo5Z+v1pOJsmrrCbDY783/tauyTnAKG2NZ3hCjN9eJwCBfNHg1Aeb7fjvHUtvfMJBFLKPaabp8uswjPwrr2N51uzB/3yJvvIwJleT5G5fjwuR2MLcgy2xmhMNvo+JPjackWSbp9TyjKpjDb06dGpjUYJb+3kJj7t0Qn4HXZ55RsaTy/sZo9DV38Za1RXx1PKNviqe9lkSRP77KnsZPmYASP04FD4EBrT5t6P3qgsjnI6r3NH0gdmZ5GHuClu6B2c7+LA/EEk2IJsr1OZmH8sMPRBG6nMMkUCq/bAQ4HnkSCSdEE3oo5uE+5x7YgrJhHQilaglF7RBpPGO4xZzROVUs327du4ck/P82Lr7xOXUeUH33ra7z83NPMmTmdluYmnl6xkuPKcgh2doAniwd+9jPu//EDlE08Dp/biVMMIYnEEwSDXax6803uf/CXHKiu4eWlT3PlR87CqaLceduN/ORXf+D4E+aQpcJ4vV5+8YtfUF1dzcaNG3E6nSlzYFkCaSUbKGW4M95Zs463Vr5JKOFgx4FGHn/mecLKyfu73uPbX/0Cf1q6gueWLuWll17inXfewe/309zcTGFhIR6vlz3vbWPaGQt57qk/ce31nwZ6cuYtN2K6CR6tm67C7CRKc7w4pMe1tdHszDZVtRGKxvGZswEko5Ti12/s4dzjRtnVyYMRjsXZ3dDJ4hmGu6M44EkREut1ccBDccBrZ1NZWHGL/CSXyCKzMv4103pKdm01doQ5eVIhPreD9lCMuvYQZ00r4asXTKeiMItv/GUTL2424jATi42Rd67PTVt3FJdTyMty29dv/vgCu41WqmoyK0231qmTi+0APRhCYs3Ka43SkwWy0Xw9szyP3Q1d1LaHmD++gLX7Wnjn/WbOmJpaENwRjhGKJhiVY3Swl8wp53dvvs+4wizK8no63erWbnK8LjrCMdstlVDGQCPL40q53gsnFHLx7HKe31hNccCL2+mgLM8Qkrykaz2nIo/XdjSkCklDFyLGwKU9FLNF3rI0S3I8jC3MSvkuI7EEneFYH9dWUcAQEkt0sr0ucsx4qWXVKaX4rSl4exq62N3QiSdp0NnHtRWKGt6NhGJPQxctpiAGI7GUB5b1nk9s6cZqfrRsB1vv+0jGsw0MFW2RHCSC4DRvzJhpzoORBpqynoDb0RPTsARFRGjq6hn5WA+9cbsctAQjLF+xgrVr13DeGYZF8tbKf1K5by/Tpk5l186d3H/PXbz08jLy8vJscfK7jE7S43TgcjiIJwzX0j/+/hLnLV5MTnYW5198OS89/1cSiQSVe3YyuryC40+YA0B2Ti7pNayBAAAgAElEQVROp5MVK1Zw22234XQa+0ueNj7WS0isupQzFn8Uh8tDJJYgGo5w91e/yJXnLeLfv/g59ry3AwUsX76Cm266Cb/fn7Lfj1/3KZb++XGcJFj+t+f42OVXAUZHIZjJBP3EWKpsITH26XI6GJXj40BriGg8wdaadiYWZxOJJ+z8+97Ud4T5wUvb+euGA2mX/2tXI3Pv+3uKe2p3vZGKeZxZX1GS400VErvz8VIc8NidrEWyu8liVK6P8UVZtAajZHuc9qi51YyRlOR4yfG5aQ1GTFeX0dmeNc3ooP+8phKXQxhrXos8v9u2SJItn2Jz8JJsTVjEE4qlZic8rTRVZMpyfTR1RQjH4va2ydfEem2lHgPcdNpEvC5HWveWNeIelWu0Z+7YfP70+ZO5dG45pea5vd/YRUswaseS9iRlRnaGY6zd10xlc5CGzjBup5Dnd3PHOUacrNTc7xUnjuHKeRUpVsMJY/LMkXzPZI6NnWGON7/PhiT3lhX7Kgn4GFeYlWKRWKP//D5CYhzbEp2A10VBlhuPy2ELxKrdTWyraedL5xrTAC3fWmfvO+B1pXFtRZleloOIEXBv7opQkO0hx+dOqYnp7dqqaglSHPDYojuSaIsE4KM/HHBxo+mHnmn+qEUp9tW0E08o/G4n0bgi1++ioiCL9q4IVS1BjivLwdUVJRY3OlyrI873u2kJRojEEnjdTjtOUZjtYXJJAL/bwRXXXM8937mPps4IM8tzaegIUxTwsHrteh576ll+8dDP+dvSv3Lfj36GIIY1BLicgiDEEwnC8QQvPfc02zatY+Hs6cQTiubGBt544w0COYY7yGH+WTGSgaaNj8biuIC2LuMHb3Xw/qwsI/Mrofjjb/6XcWPH8u3/eZhYNMqi44xJCOLxRNr9Lr7oMn754I95/vnnmXfSyXiyAsQTRkVwttdFVzhGJJ7A4+o73qlsNm4gy20BUJ7vo6atm/fqOojEEnxm0XjufX4rq/e2sGBCof09WKOzLdWGwHT2k1b78ru1tAajbK5q45zjDAvEKh48frQxYi/J8bKjtifwbYnKqBwvRdlemrvCKXNK2dNq9OqATppQyL6mILlmXUKO10VVc5BIPEFJwEuuz8X7jV0kVE9HWZrrY3ppDjvqOphUko3LPC9LSJwOSRESy+3SOzlAKcW3n3uXN3c18p8Xz+jzXZXlGcerawunWCSW0DclWSQWJ47LZ/74AtakcS1aQW1LEAF7OvSyPB+5PhdPmRXvJ1TksWpPU0q8rCsc54t/Ws/88QX4zRRih0OYXpbD506faJ/zZ06dAKTGVUab7jPLIrHiI6dOLmJrTTv17WGmjDK+W2sQUJzjYVyhnxc31xCLJ3A5HT0DggFcW06H4HU5EBHKcn12jOSfuxpxO4Xbz57MK9vr+PuWWnLM5Jz54wvY0is7rL07xqgcL+0hP7sbumjuilCY7UYpZQtJccDTJ9he2dzNmKT7YyTRFkkGxJM6AsCMMxhfvMdlZFPFegXbHSK4nYLC6Lzi5vJsr7GdFTvoCsdxOx04RMj2ujj3vMW8/Pxfqamtx+kQmpubCbXW09zUhNspXHjJFXz5G3ezbt06YvEE2YEAoWCX7Rt3OgxhqGto4t0Na6mqquL99/fy7o5dPPjggyxZsoQTZs2itrqKfTvexeUUWtvbiMfjXHDBBfz05w/xfoPRMSZPG79p43oAXnreeMSu5Xd1OYTmrggd4RjdnR2MKS9HRFj6lyW21XXmuefxu9/9ju7ubhIJxZb3DxgZZR4fp591NnfccQef/NSn6Y4mCJrZNFZn0F/AvaolSI7PleK2GJ3vp6YtZAdcz54+iknF2azdZ5zHT1fs5KKf/dNu15YDxg3bkdTRvLWniZv/sIZQNG7XUuxIyuvfXtuBx+VggjlxYEnA249ry7BIEqrnOezQ49rqnTa60JyTyfo8L8vNNlOgLIvEcu+Myu3pgM+cZnTAk4p7rIhcv4t2c+qM/KTj5Gd5cEhPwLznnJt5/O393HrmJDvWkIx1vB11HVh5GU1dYf68popTfvAK+5qCiMDxo3Ptcxid52PO2Hy217b3yfazgtqWRZKMx+Xg6gVj7c7UqtSHnk66I2TEjrZUt9kWm8W3L57Bl85LnfAz2+O0k1aKA17K8/22kFjxpVOnFKW0DYzvMsvjJMvjYlxhFvGEssWg9/QodhtN15ZVFGmJcnJ1+/6mIGMLsvC5nVwwo4z1la28sq0ej8vBnIo8mrrCKXHU9lCUXL+bqaNy2FTValgkWZ6UJz6OLcxKa5FYFvtIo4UkA+IJZVevWmR5DPeP1+VMqe+wg+0OsUeI0XhP1bm1XTiWIJFQBKNx3M6efZ84Zza3feUbfPLKS7j8vFO54IILqKuro7KyknPOPourLzyDr33pC3z3e98jllBcde0N3HzzzVz30TPJdoHTISjgr88+w+lnnYvbbYxwC7I8XHHFFTz77LM4HA6eemIJ933zq1x27qnccNWlhMNhbr31VgqLRnH+6QuZM2cOTz31FAD33HMP3/3m17jpqo/hcnsM15l5vvlZbtMqS3DTLbfx+0cf4YZLz6euusqeXv7cCz7KhRdeyIIFC5gzdy4PPvAANW3dKODaa6/D7XZzweLFZsaT0cnl+twIMoCQdNvxEYsxZgexfn8LuT4X44uymDs2n82ma2tDZSvv1XXao7h3TYvEsgrbglG+/MR6lm+t4//e2sdOs+NOLhDbVtPO1FEB+7styfHSHorZnWVjZ8R2tVhujuSOuy3YN0YCcNJEQ0isOpA8v9vOfppYbNSHWJlSpSlCYri3rIC8tY/2NK4tp0MozPb2cbet3N2I0yHcYaZQ96bMPF5yHUVTZ4T1lUantnRjNYVZHgqy3PjcDo4fbVi8cyryiMaVfR4WPRZJ+scPfHrRBNtlnCwkVqdY3WoUfO5tCvJ+YxclgfT7sRAR+3qX5BhCYv0Gdtcb8Yn54wpT2gaGy84SKSsB4sXNNXzswX+yw7RMe3+PWR4XPtNDEPD2OHxK83y2a2tvUxfjioz9XX/yOPL9bl7dXs/YAj+leUaqcPJ31N4dJdfn5iMzS9nXFGRvU5DCbI9txYBhmScLSSJhWCtjPyCLRLu2BiCeSJBIGFaGs5e5n20JidtIyQ1GzHmuTPeQZZGAURdhxFMMU9chRgcZjBgZKPfcc6/dgXhcDj52xSf42BWfINvrsieCA1i/fj3t3VH2NnUxoTib+vYQl155FV++5TP2Oq6Y8QO87JpP8bnPfT6lzSUlJdTXGz7rRYsW8fbbb7O3sYtIPEFWlvGD+4//up/uaJxJxdkEzBHPGWeexfP/XMuoHC/1HWHK8/xE4wn+7Rvftv3ineEYx5XNZvPmzWytbsfrcvDLB37Etpp2IrEEd999N3fffTeVzUFaghH7R7/67VXcdNNN5rFCdISiBLwu3E7B7epfSCpbgn2mEx+dZ6SOPr3uAJfMHo2IMLE4m2fWHyAYibHfzPxZu6+FioIse9RruT6+88IWmjojFAe8/Pjv7wHGKDhZSPY1BVOK3ayOprEzTEVBFg0dRuqviFAc6Flm1TJYLqfkTgZgQlEWJTleO3j7mUUTeLe6jasXjGXWmLyUTiO5Az5pQiGnTynmXNP1BoYIWZ1WSa9RvxG3SXVtvbWnyTxG+meaW0JiuQKNc4okiWeY6Wb23BUnVjB3rNH5W9dpU1WbnUILRupvlsfZ5xpYjCvK4tzpo/jHew1UFPjJ9RkWVkVhFhur2tjf3BMv2d8c5NTJg0/jn+t309gZoSTHy8TibP62qZruSJytNe1MLQ2Q63fhdzupbQ9xyc/f5OPzxthp3NCTAPE/f99BNK7sbKuCbE+fYxVleznQ2m17HwDK83ws2xIiFk+wvynIAjPxoSjg5VsXzeBrf97IhKJsO0ZU1x6iLM9nzHhgJgB89ITR/OdzWwjHEhRkeewMwCzTvZcsJHUdIaJx9YFZJFpIBmBnfSdZbhfxJL+6RbbXxdiCLPJ8biLmPFeJhCKR6BEdd7JFEle4HIKI4HE5TCExbsQsb09GkSfpOC5H37hCwOfC6RBazeeMeF2p6yRbTtbIaCCcDiEe7QloW7GcroiRGZM88aTP7cTlcNjpuW6n2KZ7cieU63fhNeMaydaaUoqOUMyoh4kn+Lcbr6W1oZbXXn0Vj8vJuMIs20UnInicDiJJT19UShGMxNhW005VSzenT0nNBrJSgCsK/HznslkA9rM+9jR02Rku6/a1cPa0Ufb7zpAh6C9squHqk8ZSUeDnv1/eQbbHySVzylnyzn77GlS3dnOxma4KJIlFhIqCrJRRbLHp5kgeXbZ2R8j3u/vEIUSEh6+fZw8orj5pLFcnTYCd7MZIduX43E7+7/Opj/nJ93uIJRQnTSjg5jMmpSwzUpJ7hKQ7EmdDZWtal5a9PzNYbAlvSY6Xpq5wSuaW5dL5wZUn2J+V5fooyfH2eQ67VYyYLm5m8V+Xz2JrdTsup4OigGH1WZ157zTckn4sm5RzMK9rccDDCWPySCjYWtPOtpp2zp4+ChGhNNfL37fUcaC1mxyfkdZtWXqj8/y4kpJnrKzA3llb1jEOtHaTlSQk08uM6vrVe1voCMdSBkFXzhvDu9VtLBhf2CdVuCsSJ54wYrC5PjfnzyjlhU01FGZ77HhVrs9Nnt9NZzjG8q1GzOUTC4zfjhaSIwCfy0l3NI5C4XX0vfGt0YgtGIkECQXWE2JdDiP4HY0njGlOzH14XQ772Qtel9OexgQMl5jV+fZ2p4ERe8nP6ukMXM7+hcTr6pvy2hsrpgKkJAV0hQ13TXc0bpvHTofg9xjXxGm2Mx3JLie3U+xMr+5onFgiQUVBFjVt3fzi908yozzX7lB6By49Loc9yorE4uxtCtLcFeX2R94hGIn3uUlOHJfPaVOK+PbFM2yXjjUf1srdjfa5rd3fYo+u8/xuOx01EktQUeDnqvkV/Pjv77FgQiEzRucSjiWobA7idhnFnsnnZ3ViViZSQ0fYTmG1XVtJHXdrMJoS10lmwYTCtJ8D5JoWSXHAM2gq51ULKijMdnPtwnF91i0OeFOeIb5uvzHdy0AP57I6WSvBYVppgL2NQWrbe2YwLkrjXrLcWxurUoWkqqWb0XkDd3Dl+X57YFCY7eH9xi77d9i7MDAjIcnykOd343U5bSv69R31NHZGmGHGdkbl+HhnrxFP21TVhtMhnDzJ+E6cDmFcURaJhGLO2Hye21CNx+nAnyat3Mq6CyQNEGebc3/9bbMxQef4op7fkIhwzyXGNIOWgFiZW5bVYQ0kPj6vghc21VCS47XXzfW7bBfbQ6/tYmNlq10EabnkRppjWkj6y1Ky8LmddISiiAjO/lezXVjRuDF6d5j7tKwPY2ZeZfvVPS6jJiCeUCkuCwvPAEICxuywKqHswqRkhmKRJJRRvGhNMy8idEXidlDaci+5HILP7aAzFMPlFLIzSCt0ORx0JgzXUXsohmB0ivGEj2g/2VwWXpeTeCJiFnJGCUVi5Pp60iN7C8moHB9/+vwpKZ9ZFskb7xnFfidNKGDd/lZeMdNSF04sZGPSPFd5fjejcnz85Oo5TCzOtoPLO+o6bHEaW9hz3LJeI8jGzrDt1883M7CSXUm94xaZYlkqJTmDP2VvTL6fTy2akHZZUbaXxo4wneEYv/3nHt6r68DpENvV0h9luT4qm7sRgSklAXsqletPHs/9L2+nPD99u+ZU5LNiW70RMDY7w31NXVw4a3Ta9dO32eiYre/bskgsERssRgJGR27dl2W5PoqyPbZ7aka5mcptugF9boft7ixO2vcD18wl2+tiY2Urz22oJj+rr2UJPQOI5PtjYnGALI+Tl8yan2Qh6X2uDukZmFjT5ljf/9nTS/j1p+Zz1vQSW1Dz/G77N2VZf0+tMc5tTL4Oto8oPp+PpqamAaeL8LsdKMwYST+dOvRYJNZcWsnxFJ/bsD5i8YRtkXicDnP0n7CD78lY6a79HdPhECoKs5g6KtDHR2tt43Y6cDoyExIwgnNW5lnA60q5LpYLzukwRmAKI9judg2griYup9hV9sFwzHCPOR120HMg/Oa16Y7EjXqbcCejCnK4ZE45kNloK+B1URzw8s77xkjzihMriCcUv3vzfc6aVsL4wiw6w7EUIQG4bO4YZlfkM3WUNb1Gh10bkBzALA54cTmEGnPG36auCMU5xnficAiF2anV7a3B1EyqTLEGHKVpMp0OhqKAh65InGfXVfHAip28uLmW2RX9x0csLJdLQZYnJWtselkOS+84nS+cnT5QP88UKOtJiG3BKC3BKBOLMx8pW26zMQV+RHqmBbFcm5lYJF9ZPI3ffmYBYAzwZo3JszOwrBoSK/b0+dN73IHJ+55dkc/kkoCdqtw7Y6t3e5NjQE6HMLM8l6auCCL0SRSxcDkdFAe89kwC1sy/lgiLCBfMLMPrctq/iVyfu4+VW9seoiTHm7YQdyQ4Zi2SiooKqqqqaGhI/8wIMITB+kJDfhct/dxsCaWoaw0RanDTHYnhcAiRJmt+pKgx/bcYP6zOOjfhaJwGq3Np9VLfy6poD0Vp744RyXLT1E9Asj+U2Raf28G21sFvsGAkRnNXFGn1klCGSR3JctPaHSXb46IzHKPFKcZMwu0+I7XYvCbhLDetg7SvKxwzHgDU5qOxI4zH5SDWnP4G7E1CKepbQ3Q3uOgMxehOOPnIwhncd+kYFk4s5LiyzKrRJxZnsXpvCx6ng4tOGM1/L9vOmVNL+NEnZvPw67sJRuK2v7m3tZDtdVFR4GdbTQfRuFGAmiyADodQatYItASNyTaTR8jGfFupMZJ0VeWDYXUkpRlYJANhte21HQ0EvC5+9an5GfnRLSEpzPbYFgIYI+uB3FQnTyykOODl2fUHuHDWaN43Ex4mDPLc9WSKss2YU7bX/k3m+FycNb2EP729b9BnuKdj1phc/vFeA2Py/XYnfFxZDvlZbm4+cxKPrdxLRziWYpFYlOb6mFYasAcMfdtrfJ7d696YNSaP1XtbGJ3rG7CDL8/3s89MKOg9wEnGFhK/2x6ciMCFM8t46d1au0D1g+CYFRK3283Eif0HGMEYpV9z7zKCkTjfvXwWN5w4Pu16Simu/PbLfObUCazY2sSM8lwe+uTxADy34QBfXroBgG9cOJ0vzJtCVUuQy+9/Db/byeZ7L7BdXhbPrq/izqUb+eUN81lwfNlBn9st97/KJ+aP5csnTR103Ve313HzkjU8+4VTaegIc8vStTx/x+mcOiobpWDmPctwOozA97b/ujDlmvz6U/M5aZD2vbKtjpufMPZ/65K3uPHUCXzzY8dnfC5f/sk/8JqB3u9cOhO3202BGz51SvrvIh0TirJZvbeFikKj03jnPxbbVp81arTqCtLdsPPGFfDWnia8bgdlub4+BZJWIaQVvB+dJDS9s6Rag0N1bRntTFd7cTBYo+WVuxuZXZFvj64Hw3LhFWV7bNeNx+kYVNhcTgeXzS3nD6v20tIVYa9ZoW65HDPhYyeMJmYGnLO9TjrDMYqyPZw1rYSN91wwpFH3LLN40qp9Abh6wVgumzsGn9vJ7LF5/GtXU1ohAXjok/NsV1lvLOHrLSSWy3NcP24tixnlubywMfUZNdb3n4w1uEh2bc0sz+Xi2eW89G5tv1bPSHDMurYywaqWBdLGMixExJ4qwxotWSSn71ojldF5fjxOB7Mr8vqICBgmdJbHydTSgx+5Arz8lTP54jmTM1o3edpxq96hyJxWIdvrYlSOl3hC2dkpDofYN99grinocQ1srzWqza0gYKbMrsizs4VmJdUUHAxWpzXedIUlC4H1XR0YQEhOmVREfUeYf+1qTJuXX5ZnFEJaneSkpE6yKNtjTysSixtP7Otde5AJlusp2a00FKyOMRRNMPsgrmepnUDgsYPJFYX+lELd/rhy3hiiccULm2t4v9GY12rcQQSBZ5TnctdHj0OkJ23aErOhum6s35IVHwHjPrb2N9dMXe4v/jKtNKdfy7Iw0DfYDj0B9/GFA4vorPI82kPGPFp2jCSNN6THteWy3WynTS7mtClFuBxyUGI9XI5ZiyRTjh+dy/r9rWm/yGRKcrzUd4ToDMdSgmyTSwKIGHNxWSMVp0P47GkT+u0YJ5cE2HrfhUNuc3/5+elIERJz5FyY5LqYUJRNfUc4JRYzY3Qua/e1ZCQK1jQYVhAwE/FJZvaYPJ5ZdwCHYGfXHCxW5lY6F0jAa5z/QBbJKWbmTl17OO0I3qoR2NPQaT7DIzWG0tARtusBgCHFSMYWZOFxOpgxOjN3Xn9YFgmQ8hTBweixSLx2WvP4DMVgxuhcppfm8Oy6KsYVZlGe5x+yAFi/7cI09RsHw9jCLH56zZw+E0paXHvSOGBo6bPF/VgkE4sDzBuXzxnTBrYCZ5ri9u6BNjtGkm4gaw0ucv1uCrI99vnkZ3l45gunDsnlN1S0kAyCNfpOZ1omMyrHy676ToKReMoPyO9xUlHgp7K52x6pAPzHQbh3RhIrG6TdtEgCXlfKTT6+KIt39janBBavOWks2V5XRjdzUcCDCHbK6cEKyQkVxshwWmmOHXw/WCx/fLpRcKCXRZIu6DyxONu2ONO5C8ryfERiCdZXtjImP7WTLM31EYoas8r2zLN18J1gWZ6Pd7/zkbTzjh0Mya6ag7HwrCB/UaDHtZWpVSEiXDFvDD98aTsHWruHFCOysO6tomEKCRiJF/0xtjCLr3/kuCHtd0yBH5/b0ef6OB3CM184bdDtp5fl4HQIW6rb6Y7GjSle0nguSnO9+Nw90/Ukn8/sivw+648k2rU1CBfMKOWyueX2bK/9UZLTk2ffe/Qw1ZwEzhqpHEmkWiSRlBEr9LiFki2SWWPybFfDYLidDgqzeqrDDzYdcWZ5Li6HDNmtBUYQ9esfmc6lc8v7LLNGuAdajCK0dJlyImLXWaQLYFrB5tV7m23rxyJ5WnR7nq0huLaAYYsIGK6ggNd4jsrEgxixluf7OXVyEadMKiLb4+TG0yZw6dwxGW9/+dwxiBhW3cEE2nuTfYgskpGkMNvD6rsXp8w2cDD43E6mjgqwpbqNtu6oPdjrTX6WcZzzjh/acQ4lWkgGoTTXx4PXntjHTO3NqByfPRFj73WtFNLCwJH34/e6nPjdxoOQmpMe/GNh3fSFQ+z8wBDZhDJSoQ82PuBzO3n4hvn2lNtDweEQvnjOlLSB0+QYyUBBcMu9lS7l2HLxhaKJfoWkpi3UM8/WEFxbh5LigIcZ5bkZxTcs3E4Hj998CqdMKrIL6OYPUnuSTFmej9MmGy6d3tfoYMjpFSM5Usnxpa8xyZQZ5bm8W91O+yB1R8M9zqFCu7YOEcn55r1jFJ8+dQJTRgUOKnbxQZLnd9NqPpeht+vGKpwaijvGoiTHy/baDsrz/UP60Z8/o3TIxx4M6zsJxxID3rCXzx1DdySetnBvdFIxXu/Rtl2w2Bay626Gcy0PBfdeOvOwtOHKeWN4c1fjsITkULq2jmRmlRuxwVV7muw6lyOZI7NnOwoZNYCQjMn323PfHIlYz69o7oowp5dvdXJJgNF5vpTsloPFEtkPqsr2YEi2HgcSkmyvi8/3mrfKojjbaz/BbmJJaidp1V/UtIXsONvhtkjOnn54XCGXzinH6RD7gVxD4WhwbR0KzppewuS3s6koyOKGg0h1P1xoITlEpFgkA6QKH4nk+d00dUVo7uobI/F7nKz65nnD2r91bcoHmV/pcBDIUEgGwipKPNDa3Sfu4HE5KA54qG0P0RVx4XE6+vV5f9gxakoyj6ukw3JFftiFZHJJgFe+dvbhbkbG6BjJISJZSDKZg+pIYp75fO1YQo2I79lKAR7dz3xMhxOnQ+xpaoYqJGAUJbockjZdtDTXR21bN9trO5gyKjDgdDuagbG+o/6eZaI5PBxdPd4RTHIgd6DixSORr54/jU1Vrazc3TQivmfbIjkCXVtgWCXBSHxYQjKtNIdwLJE2TXN0nvEs+eausB1w1gyNy08cw5h8/7ALMzWHlqOrxzuCcTsd9jMCBsvwOtLwuBw8fP18fvH6Ls6Yeug7OqvSe+ow6gdGkoA5o/BwXE7fvniGnbXXm9JcH2/uaiQUTdgzJWiGRsDr4pwhptVqRo6jq8c7whmV4zWF5IOZcfNQkpflPqg5sA6GWWPyeOPr5ww6x9DhwkopHY5F4nM7+63WHp3ns58/o4VE82FkRGMkInKhiOwQkV0iclea5V4RedJc/raITDA/94jIoyKyWUQ2isjZSdu8bu5zg/l3xAxPSnK8eJyOjB4odaxxpIoI9CRHDEdIBiL5GeuDFbZqNEcjI2aRiIgT+F/gfKAKWC0iS5VSW5NW+xzQopSaIiLXAvcD1wA3AyilTjCF4iUROUkpZfkOrldKrRmptg+VUTm+oy4+ounJ3BopIbGKEvOz3MN+nohGcyQykhbJQmCXUmqPUioCPAFc1mudy4DHzNd/Ac4To2JtBvAKgFKqHmgFFoxgWw8Jt589mR99YvbhbobmILEmbhwpIbEq36eX5hwRVcgazaFmJIVkDFCZ9L7K/CztOkqpGNAGFAEbgctExCUiE4H5QHJF36OmW+vb0s+dKSK3iMgaEVkz0MOrDiVTRgU497iRq8LWjAw5H5BrK9MHcWk0RxsjKSTpOvjez7Xtb51HMIRnDfAAsBKImcuvV0qdAJxh/n0q3cGVUr9WSi1QSi0oKRl6Ja3mw89Iu7ZyfG6+ddHxfGrRkV+hrNEMhZF06FeRakVUANX9rFMlIi4gD2hWxgPD77RWEpGVwE4ApdQB83+HiDyO4UL7w0idhObDz5yx+cwZmz+iFef9Ta+i0XwYGEmLZDUwVUQmiogHuBZY2mudpcBnzNdXAa8qpZSIZIlINoCInA/ElFJbTVdXsfm5G7gYeHcEz0FzDHD+jFKe+/yjHycAABO5SURBVOJpuuJcoxkiI2aRKKViInIHsAxwAo8opbaIyH3AGqXUUuB3wB9FZBfQjCE2AKOAZSKSAA7Q477ymp+7zX2uAH4zUueg0Wg0msERw4v04WbBggVqzZojLltYo9FojmhEZK1SatCMWT1po0aj0WiGhRYSjUaj0QwLLSQajUajGRZaSDQajUYzLLSQaDQajWZYaCHRaDQazbDQQqLRaDSaYaGFRKPRaDTDQguJRqPRaIaFFhKNRqPRDAstJBqNRqMZFlpINBqNRjMstJBoNBqNZlhoIdFoNBrNsNBCotFoNJphoYVEo9FoNMNCC4lGo9FohoUWEo1Go9EMCy0kGo1GoxkWWkg0Go1GMyy0kGg0Go1mWGgh0Wg0Gs2w0EKi0Wg0mmGhhUSj0Wg0w0ILiUaj0WiGhRYSjUaj0QwLLSQajUajGRZaSDQajUYzLDISEhF5WkQuEhEtPBqNRqNJIVNheBj4JLBTRH4oIsdlspGIXCgiO0Rkl4jclWa5V0SeNJe/LSITzM89IvKoiGwWkY0icnbSNvPNz3eJyM9ERDI8B41Go9GMABkJiVJqhVLqemAesBdYLiIrReRGEXGn20ZEnMD/Ah8FZgDXiciMXqt9DmhRSk0Bfgrcb35+s3ncE4DzgR8nWUMPA7cAU82/CzM5B41Go9GMDBm7qkSkCPgs8HlgPfAghrAs72eThcAupdQepVQEeAK4rNc6lwGPma//ApxnWhgzgFcAlFL1QCuwQERGA7lKqVVKKQX8Abg803PQaDQazaEn0xjJM8A/gSzgEqXUpUqpJ5VS/wYE+tlsDFCZ9L7K/CztOkqpGNAGFAEbgctExCUiE4H5wFhz/apB9mm1+RYRWSMiaxoaGjI5TY1Go9EMAVeG6z2klHo13QKl1IJ+tkkXu1AZrvMIcDywBtgHrARiGe7TatevgV8DLFiwIO06Go1Goxk+mbq2jheRfOuNiBSIyBcG2aYKw4qwqACq+1tHRFxAHtCslIoppe5USs1VSl0G5AM7zfUrBtmnRqPRaD5AMhWSm5VSrdYbpVQLZkB8AFYDU0Vkooh4gGuBpb3WWQp8xnx9FfCqUkqJSJaIZAOIyPlATCm1VSlVA3SIyClmLOXTwHMZnoNGo9FoRoBMXVsOEREzwG1lZHkG2kApFRORO4BlgBN4RCm1RUTuA9YopZYCvwP+KCK7gGYMsQEYBSwTkQRwAPhU0q5vB34P+IGXzD+NRqPRHCbE1IaBVxL5ETAB+CVGTOI2oFIp9bURbd0hYsGCBWrNmjWHuxkajUZzVCEiaweIg9tkapH8O3ArhjUgwN+B3w69eRqNRqP5sJCRkCilEhiFgA+PbHM0Go1Gc7SRkZCIyFTgBxiFgj7rc6XUpBFql0aj0WiOEjLN2noUwxqJAedgVJT/caQapdFoNJqjh0yFxK+UegUjOL9PKXUvcO7INUuj0Wg0RwuZBttD5qSJO82U3gMYKboajUajOcbJ1CL5CsY8W1/CmPfqBnoKCTUajUZzDDOoRWIWH16tlPo60AncOOKt0mg0Gs1Rw6AWiVIqDszXD5DSaDQaTToyjZGsB54TkT8DXdaHSqlnRqRVGo1GozlqyFRICoEmUjO1FKCFRKPRaI5xMq1s13ERjUaj0aQl08r2R0nzACml1E2HvEUajUajOarI1LX1QtJrH3AF+oFSGo1GoyFz19bTye9FZAmwYkRapNFoNJqjikwLEnszFRh3KBui0Wg0mqOTTGMkHaTGSGoxnlGi0Wg0mmOcTF1bOSPdEI1Go9EcnWTk2hKRK0QkL+l9vohcPnLN0mg0Gs3RQqYxknuUUm3WG6VUK3DPyDRJo9FoNEcTmQpJuvUyTR3WaDQazYeYTIVkjYj8REQmi8gkEfkpsHYkG6bRaDSao4NMheTfgAjwJPAU0A18caQapdFoNJqjh0yztrqAu0a4LRqNRqM5Csk0a2u5iOQnvS8QkWUj1yyNRqPRHC1k6toqNjO1AFBKtaCf2a7RaDQaMheShIjYU6KIyATSzAas0Wg0mmOPTFN47wbeFJF/mO/PBG4ZmSZpNBqN5mgiI4tEKfUysADYgZG59TWMzK0BEZELRWSHiOwSkT7BehHxisiT5vK3TUsHEXGLyGMisllEtonIN5O22Wt+vkFE1mR0lhqNRqMZMTKdtPHzwJeBCmADcAqwitRH7/bexgn8L3A+UAWsFvn/7d1/rGRlfcfx98dd2OhiEWFplR/uItSUhhbxlpJaTJXGgrGutlAWKCUtCW0iiaRpIsbaGv4qrdakCaligC4UhUilvWkiKGrxR8KPu5Qfi4CuW5QrK7sKAcUqLnz7x3luHS5z9967h5m54PuVTO6ZZ5459zvPnJnPnHNmzsl0VX1toNu5wGNVdWSSTcDFwOnAacCaqjomycuAryX5ZFU92O735qr63jIepyRpRJa6j+Q9wG8A36qqNwOvB3Ytcp/jgW1Vtb2qngKuATbO67MR2NymrwNOShK6/S9rk6wGXkr3G5YnllirJGmMlhokP66qH0O3Oaqq7gdet8h9DgEeGrg+29qG9qmq3cDjwIF0ofIksAP4NvChqnq03aeAzybZkmTB/TRJzksyk2Rm167FMk+StLeWurN9tv2O5N+BzyV5jMVPtZshbfO/6bVQn+OBp4FXAwcAX05yU1VtB95YVQ8nObjVcn9Vfek5M6m6FLgUYGpqym+YSdKILPWX7e9qkx9M8kVgf+CGRe42Cxw2cP1Qnhs+c31m22as/YFHgTOBG6rqp8DOJF+l29m/vaoebjXtTHI9Xeg8J0gkSeOx7FPtVtXNVTXd9nvsye3AUUk2JNkX2ARMz+szDZzTpk8FvlBVRbc56y3prKXbuX9/krVJXg7Q2t8KbF3uY5AkPX9Gdij4qtqd5HzgRmAVcHlV3ZvkImCmqqaBy4CrkmyjWxPZ1O5+CXAFXUgEuKKq7k5yBHB9tz+e1cAn2leTJUkTkm4F4MVtamqqZmb8yYkkLUeSLVU1tVi/ZW/akiRpkEEiSerFIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvBokkqReDRJLUi0EiSerFIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvBokkqReDRJLUi0EiSerFIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvBokkqReDRJLUi0EiSerFIJEk9WKQSJJ6GWmQJDk5yQNJtiW5cMjta5Jc226/Ncn61r5Pks1J7klyX5L3LXWekqTxGlmQJFkFXAKcAhwNnJHk6HndzgUeq6ojgY8AF7f204A1VXUM8Abgz5OsX+I8JUljNMo1kuOBbVW1vaqeAq4BNs7rsxHY3KavA05KEqCAtUlWAy8FngKeWOI8JUljNMogOQR4aOD6bGsb2qeqdgOPAwfShcqTwA7g28CHqurRJc5TkjRGq0c47wxpqyX2OR54Gng1cADw5SQ3LXGe3YyT84DzAA4//PAllixJWq5RrpHMAocNXD8UeHihPm0z1v7Ao8CZwA1V9dOq2gl8FZha4jwBqKpLq2qqqqbWrVv3PDwcSdIwowyS24GjkmxIsi+wCZie12caOKdNnwp8oaqKbnPWW9JZC5wA3L/EeUqSxmhkm7aqaneS84EbgVXA5VV1b5KLgJmqmgYuA65Kso1uTWRTu/slwBXAVrrNWVdU1d0Aw+Y5qscgSVpcuhWAF7epqamamZmZdBmS9IKSZEtVTS3Wz1+2S5J6MUgkSb0YJJKkXgwSSVIvBokkqReDRJLUi0EiSerFIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvBokkqReDRJLUi0EiSerFIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvBokkqReDRJLUi0EiSerFIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvBokkqZeRBkmSk5M8kGRbkguH3L4mybXt9luTrG/tZyW5c+DyTJJj223/1eY5d9vBo3wMkqQ9G1mQJFkFXAKcAhwNnJHk6HndzgUeq6ojgY8AFwNU1dVVdWxVHQucDTxYVXcO3O+suduraueoHoMkaXGjXCM5HthWVdur6ingGmDjvD4bgc1t+jrgpCSZ1+cM4JMjrFOS1MMog+QQ4KGB67OtbWifqtoNPA4cOK/P6Tw3SK5om7U+MCR4AEhyXpKZJDO7du3a28cgSVrEKINk2Bt8LadPkt8EflRVWwduP6uqjgFObJezh/3zqrq0qqaqamrdunXLq1yStGSrRzjvWeCwgeuHAg8v0Gc2yWpgf+DRgds3MW9tpKq+0/7+IMkn6DahXfn8lt585kL47j0jmbUkjdwvHQOn/N3I/80o10huB45KsiHJvnShMD2vzzRwTps+FfhCVRVAkpcAp9HtW6G1rU5yUJveB3g7sBVJ0sSMbI2kqnYnOR+4EVgFXF5V9ya5CJipqmngMuCqJNvo1kQ2DcziTcBsVW0faFsD3NhCZBVwE/DxUT2GcSS5JL3Qpa0AvKhNTU3VzMzMpMuQpBeUJFuqamqxfv6yXZLUi0EiSerFIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvPxe/I0myC/jWXt79IOB7z2M5zxfrWr6VWpt1Lc9KrQtWbm17W9drqmrRgxX+XARJH0lmlvKDnHGzruVbqbVZ1/Ks1Lpg5dY26rrctCVJ6sUgkST1YpAs7tJJF7AA61q+lVqbdS3PSq0LVm5tI63LfSSSpF5cI5Ek9WKQSJJ6MUgWkOTkJA8k2ZbkwgnXcliSLya5L8m9Sd7T2j+Y5DtJ7myXt02gtgeT3NP+/0xre2WSzyX5Rvt7wJhret3AmNyZ5IkkF0xqvJJcnmRnkq0DbUPHKJ1/asvd3UmOG3Nd/5Dk/va/r0/yita+Psn/DozdR8dc14LPXZL3tfF6IMnvjbmuawdqejDJna19nOO10PvD+JaxqvIy70J39sVvAkcA+wJ3AUdPsJ5XAce16ZcDXweOBj4I/NWEx+pB4KB5bX8PXNimLwQunvBz+V3gNZMaL7qzfR4HbF1sjIC3AZ8BApwA3Drmut4KrG7TFw/UtX6w3wTGa+hz114Hd9GdPXVDe92uGldd827/MPA3Exivhd4fxraMuUYy3PHAtqraXlVP0Z03fuOkiqmqHVV1R5v+AXAfcMik6lmCjcDmNr0ZeOcEazkJ+GZV7e2RDXqrqi/RnUp60EJjtBG4sjq3AK9I8qpx1VVVn62q3e3qLcCho/jfy61rDzYC11TVT6rqf4BtdK/fsdaVJMAfAZ8cxf/ekz28P4xtGTNIhjsEeGjg+iwr5I07yXrg9cCtren8tnp6+bg3ITUFfDbJliTntbZfrKod0C3kwMETqGvOJp794p70eM1ZaIxW0rL3Z3SfXOdsSPLfSW5OcuIE6hn23K2U8ToReKSqvjHQNvbxmvf+MLZlzCAZLkPaJv496ST7Af8GXFBVTwD/DLwWOBbYQbdqPW5vrKrjgFOAdyd50wRqGCrJvsA7gE+1ppUwXotZEctekvcDu4GrW9MO4PCqej3wl8AnkvzCGEta6LlbEeMFnMGzP7CMfbyGvD8s2HVIW68xM0iGmwUOG7h+KPDwhGoBIMk+dAvJ1VX1aYCqeqSqnq6qZ4CPM6JV+j2pqofb353A9a2GR+ZWldvfneOuqzkFuKOqHmk1Tny8Biw0RhNf9pKcA7wdOKvaRvW26ej7bXoL3b6IXx5XTXt47lbCeK0G/gC4dq5t3OM17P2BMS5jBslwtwNHJdnQPtVuAqYnVUzb/noZcF9V/eNA++B2zXcBW+ffd8R1rU3y8rlpuh21W+nG6pzW7RzgP8ZZ14BnfUqc9HjNs9AYTQN/0r5ZcwLw+NzmiXFIcjLwXuAdVfWjgfZ1SVa16SOAo4DtY6xroeduGtiUZE2SDa2u28ZVV/O7wP1VNTvXMM7xWuj9gXEuY+P4VsEL8UL3zYav032SeP+Ea/ltulXPu4E72+VtwFXAPa19GnjVmOs6gu4bM3cB986NE3Ag8HngG+3vKycwZi8Dvg/sP9A2kfGiC7MdwE/pPg2eu9AY0W12uKQtd/cAU2Ouaxvd9vO55eyjre8ftuf4LuAO4PfHXNeCzx3w/jZeDwCnjLOu1v4vwF/M6zvO8Vro/WFsy5iHSJEk9eKmLUlSLwaJJKkXg0SS1ItBIknqxSCRJPVikEgrWJLfSfKfk65D2hODRJLUi0EiPQ+S/HGS29q5Jz6WZFWSHyb5cJI7knw+ybrW99gkt+Rn5/yYO0/EkUluSnJXu89r2+z3S3JduvOEXN1+ySytGAaJ1FOSXwFOpzuA5bHA08BZwFq6Y30dB9wM/G27y5XAe6vq1+h+WTzXfjVwSVX9OvBbdL+ihu5orhfQnWPiCOCNI39Q0jKsnnQB0ovAScAbgNvbysJL6Q6Q9ww/O5DfvwKfTrI/8Iqqurm1bwY+1Y5ZdkhVXQ9QVT8GaPO7rdpxnNKdgW898JXRPyxpaQwSqb8Am6vqfc9qTD4wr9+ejke0p81VPxmYfhpft1ph3LQl9fd54NQkB8P/nyv7NXSvr1NbnzOBr1TV48BjAyc6Ohu4ubrzR8wmeWebx5okLxvro5D2kp9spJ6q6mtJ/pruTJEvoTs67LuBJ4FfTbIFeJxuPwp0h/T+aAuK7cCftvazgY8luajN47QxPgxpr3n0X2lEkvywqvabdB3SqLlpS5LUi2skkqReXCORJPVikEiSejFIJEm9GCSSpF4MEklSL/8HuAcuHE2tYGwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist3_2.history['acc'])\n",
    "plt.plot(hist3_2.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train Accuracy', 'Test Accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize history for loss\n",
    "plt.plot(hist3_2.history['loss'])\n",
    "plt.plot(hist3_2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
